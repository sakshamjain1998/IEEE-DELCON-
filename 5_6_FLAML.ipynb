{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiV6v9rz955V",
        "outputId": "5fdaef6c-9c64-469c-ddc9-1e1db0298fcb"
      },
      "source": [
        "!pip install flaml[notebook]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml[notebook]\n",
            "  Downloading FLAML-0.9.2-py3-none-any.whl (139 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 61 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 92 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 102 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 112 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 122 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 133 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 139 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.1.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.90)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.0)\n",
            "Collecting rgf-python\n",
            "  Downloading rgf_python-3.11.0-py3-none-manylinux1_x86_64.whl (757 kB)\n",
            "\u001b[K     |████████████████████████████████| 757 kB 58.1 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.26\n",
            "  Downloading catboost-1.0.3-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 61 kB/s \n",
            "\u001b[?25hCollecting openml==0.10.2\n",
            "  Downloading openml-0.10.2.tar.gz (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 39.0 MB/s \n",
            "\u001b[?25hCollecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.8.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml[notebook]) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]) (3.0.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.2.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (7.6.5)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->flaml[notebook]) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->flaml[notebook]) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]) (3.0.6)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (21.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.26->flaml[notebook]) (1.3.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->flaml[notebook]) (1.11.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (1.24.3)\n",
            "Building wheels for collected packages: openml, liac-arff\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.10.2-py3-none-any.whl size=190318 sha256=015a45246f67d84484d5f894625c4343d2271ae7fbf3522727e7d4b1dc3ddd24\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/9e/f3/6a5ebf16527d7fe22d9bc1652bc9beb5dc9fcfdeb75e805400\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=de4165bd04de7b53d6d041807d84fa61381715f8e7c3b67922ae9ed68735a1a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built openml liac-arff\n",
            "Installing collected packages: xmltodict, lightgbm, liac-arff, rgf-python, openml, flaml, catboost\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-1.0.3 flaml-0.9.2 liac-arff-2.5.0 lightgbm-3.3.1 openml-0.10.2 rgf-python-3.11.0 xmltodict-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKC3UEeV_YS6",
        "outputId": "cbae46fb-a026-4427-b586-c0c0ec8ff621"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (3.3.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.1.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPEfQCRfbCvQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NyRP6du96y3"
      },
      "source": [
        "# common imports\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import randint\n",
        "\n",
        "# models libraries\n",
        "from lightgbm import LGBMRegressor,LGBMClassifier\n",
        "from sklearn.svm import SVR\n",
        "# sklearn imports \n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# hyperopt imports to perform bayesian optimisation \n",
        "from hyperopt import Trials, anneal, fmin, hp, tpe\n",
        "\n",
        "''' import AutoML class from flaml package '''\n",
        "from flaml import AutoML\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-6 Dataset"
      ],
      "metadata": {
        "id": "bONcT0_qyGv6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTSSogMbIg4"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using balanced datasets independently"
      ],
      "metadata": {
        "id": "4rWR0kfJj36G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('5-6_Balanced_Stunting.csv')\n",
        "df2 = pd.read_csv('5-6_Balanced_Wasting.csv')\n",
        "df3 = pd.read_csv('5-6_Balanced_Stunted_Wasting.csv')\n",
        "df1 = df1.drop(['Unnamed: 0'], axis =1)\n",
        "df2 = df2.drop(['Unnamed: 0'], axis = 1)\n",
        "df3 = df3.drop(['Unnamed: 0'], axis =1)"
      ],
      "metadata": {
        "id": "X_JZb_Xsap3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "fq6GYqrfqWgM",
        "outputId": "d15ae47a-6b97-4f5f-a6f1-f86be5bf1049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-944bb892-fc58-4757-bccb-f43e9a21a4a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>area</th>\n",
              "      <th>religion</th>\n",
              "      <th>caste</th>\n",
              "      <th>type of family</th>\n",
              "      <th>father's education</th>\n",
              "      <th>father's occupation</th>\n",
              "      <th>mother's education</th>\n",
              "      <th>mother's occupation</th>\n",
              "      <th>total family members</th>\n",
              "      <th>exposure to mass media</th>\n",
              "      <th>Source of drinking water</th>\n",
              "      <th>Toilet Facility</th>\n",
              "      <th>mother's age</th>\n",
              "      <th>mother's bmi</th>\n",
              "      <th>child's age</th>\n",
              "      <th>sex of child</th>\n",
              "      <th>birth weight</th>\n",
              "      <th>initiation of bf(early initiation)</th>\n",
              "      <th>wealth index</th>\n",
              "      <th>months of bf</th>\n",
              "      <th>history of illness</th>\n",
              "      <th>immunization</th>\n",
              "      <th>index to birth history</th>\n",
              "      <th>no of living children</th>\n",
              "      <th>sex of household head</th>\n",
              "      <th>dietary score</th>\n",
              "      <th>H/A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39046</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39047</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39048</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39049</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39050</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39051 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-944bb892-fc58-4757-bccb-f43e9a21a4a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-944bb892-fc58-4757-bccb-f43e9a21a4a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-944bb892-fc58-4757-bccb-f43e9a21a4a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       state  area  religion  ...  sex of household head  dietary score  H/A\n",
              "0          4     0         1  ...                      1              0    1\n",
              "1          4     0         2  ...                      1              0    1\n",
              "2          4     0         1  ...                      1              0    0\n",
              "3          4     0         1  ...                      1              0    1\n",
              "4          4     0         0  ...                      1              0    0\n",
              "...      ...   ...       ...  ...                    ...            ...  ...\n",
              "39046      1     0         1  ...                      1              0    1\n",
              "39047      1     1         1  ...                      1              0    1\n",
              "39048      1     0         1  ...                      1              0    1\n",
              "39049      0     0         1  ...                      1              0    1\n",
              "39050      1     1         1  ...                      1              0    1\n",
              "\n",
              "[39051 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df1.drop(['H/A'], axis = 1)\n",
        "x2 = df2.drop(['W/H'], axis = 1)\n",
        "x3 = df3.drop(['HAWH'], axis = 1)"
      ],
      "metadata": {
        "id": "bMWpFzQtbCFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = df1['H/A']\n",
        "y2 = df2['W/H']\n",
        "y3 = df3['HAWH']"
      ],
      "metadata": {
        "id": "ml-pAANGbFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.3, random_state=96, stratify = y1)\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.3, random_state=103, stratify = y2)\n",
        "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.3, random_state=48, stratify = y3)"
      ],
      "metadata": {
        "id": "fB_VJx9ObFgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using unbalanced dependent datasets"
      ],
      "metadata": {
        "id": "wmWo3hL7j7rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('New_Dataset_5-6.csv')"
      ],
      "metadata": {
        "id": "pErZmyB2kGcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "zTURb2ARqNvs",
        "outputId": "86a50c85-62c6-4fc0-ae9f-f16fa3a467cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec3d2f6d-cf3c-4bfc-9759-19cbd82bdbe8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>state</th>\n",
              "      <th>area</th>\n",
              "      <th>religion</th>\n",
              "      <th>caste</th>\n",
              "      <th>type of family</th>\n",
              "      <th>father's education</th>\n",
              "      <th>father's occupation</th>\n",
              "      <th>mother's education</th>\n",
              "      <th>mother's occupation</th>\n",
              "      <th>total family members</th>\n",
              "      <th>exposure to mass media</th>\n",
              "      <th>Source of drinking water</th>\n",
              "      <th>Toilet Facility</th>\n",
              "      <th>mother's age</th>\n",
              "      <th>mother's bmi</th>\n",
              "      <th>child's age</th>\n",
              "      <th>sex of child</th>\n",
              "      <th>birth weight</th>\n",
              "      <th>initiation of bf(early initiation)</th>\n",
              "      <th>wealth index</th>\n",
              "      <th>months of bf</th>\n",
              "      <th>history of illness</th>\n",
              "      <th>immunization</th>\n",
              "      <th>index to birth history</th>\n",
              "      <th>no of living children</th>\n",
              "      <th>sex of household head</th>\n",
              "      <th>dietary score</th>\n",
              "      <th>H/A</th>\n",
              "      <th>W/A</th>\n",
              "      <th>W/H</th>\n",
              "      <th>Bmi</th>\n",
              "      <th>HAWH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>OBC</td>\n",
              "      <td>2</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>underweight</td>\n",
              "      <td>24-36</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Muslim</td>\n",
              "      <td>OBC</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>No education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>6-12</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>18-24</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Christian</td>\n",
              "      <td>SC</td>\n",
              "      <td>2</td>\n",
              "      <td>No education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>No education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>6-</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38054</th>\n",
              "      <td>38054</td>\n",
              "      <td>51550</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>No education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>underweight</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorest</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38055</th>\n",
              "      <td>38055</td>\n",
              "      <td>51551</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>1</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorest</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38056</th>\n",
              "      <td>38056</td>\n",
              "      <td>51552</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>24-36</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.5+</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Poorer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38057</th>\n",
              "      <td>38057</td>\n",
              "      <td>51553</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>7</td>\n",
              "      <td>No</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>36-48</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.5+</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38058</th>\n",
              "      <td>38058</td>\n",
              "      <td>51554</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>sales</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>healthy</td>\n",
              "      <td>36-48</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.5-</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38059 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec3d2f6d-cf3c-4bfc-9759-19cbd82bdbe8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec3d2f6d-cf3c-4bfc-9759-19cbd82bdbe8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec3d2f6d-cf3c-4bfc-9759-19cbd82bdbe8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1        state   area  ... W/A W/H  Bmi HAWH\n",
              "0               0             0  South_India  Rural  ...   1   1    0    1\n",
              "1               1             1  South_India  Rural  ...   0   0    0    0\n",
              "2               2             2  South_India  Rural  ...   0   0    0    0\n",
              "3               3             3  South_India  Rural  ...   0   0    0    0\n",
              "4               4             6  South_India  Rural  ...   0   0    0    0\n",
              "...           ...           ...          ...    ...  ...  ..  ..  ...  ...\n",
              "38054       38054         51550   East_India  Rural  ...   1   0    0    0\n",
              "38055       38055         51551   East_India  Rural  ...   1   0    0    0\n",
              "38056       38056         51552   East_India  Rural  ...   1   0    0    0\n",
              "38057       38057         51553   East_India  Rural  ...   0   0    0    0\n",
              "38058       38058         51554   East_India  Rural  ...   0   0    0    0\n",
              "\n",
              "[38059 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN4RrCSp_rVr"
      },
      "source": [
        "def split_X_y(data):\n",
        "  X = data.drop('H/A',axis = 1)\n",
        "  X = X.drop('W/A',axis = 1)\n",
        "  X = X.drop('W/H',axis = 1)\n",
        "  X = X.drop('Bmi',axis = 1)\n",
        "  X = X.drop('HAWH', axis = 1)\n",
        "  y1 = data['W/A']\n",
        "  y2 = data['H/A']\n",
        "  y3 = data['W/H']\n",
        "  y4 = data['Bmi']\n",
        "  y5 = data['HAWH']\n",
        "  y1 = y1.to_frame()  # convert y outputs from series to dataframe\n",
        "  y2 = y2.to_frame()\n",
        "  y3 = y3.to_frame()\n",
        "  y4 = y4.to_frame()\n",
        "  y5 = y5.to_frame()\n",
        "  print(X.shape, 'X shape')\n",
        "  print(y1.shape, 'y1 shape')\n",
        "  print(y2.shape, 'y2 shape')\n",
        "  print(y3.shape, 'y3 shape')\n",
        "  print(y4.shape, 'y4 shape')\n",
        "  print(y5.shape, 'y5 shape')\n",
        "  return X, y1, y2, y3, y4, y5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arTlsoqLAidI"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.25, random_state = 456)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8L6CGxVAig8",
        "outputId": "fe8e1626-5655-4a05-d79a-0713758a92a5"
      },
      "source": [
        "X_train, y1_train, y2_train, y3_train, y4_train, y5_train = split_X_y(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28544, 27) X shape\n",
            "(28544, 1) y1 shape\n",
            "(28544, 1) y2 shape\n",
            "(28544, 1) y3 shape\n",
            "(28544, 1) y4 shape\n",
            "(28544, 1) y5 shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKcifHfbAilk",
        "outputId": "21ec08e0-4a90-4079-c25b-b397affc2286"
      },
      "source": [
        "X_test, y1_test, y2_test, y3_test, y4_test, y5_test= split_X_y(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9515, 27) X shape\n",
            "(9515, 1) y1 shape\n",
            "(9515, 1) y2 shape\n",
            "(9515, 1) y3 shape\n",
            "(9515, 1) y4 shape\n",
            "(9515, 1) y5 shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZWed-fIBXWq"
      },
      "source": [
        "y1_test_np = y1_test.to_numpy()\n",
        "y2_test_np = y2_test.to_numpy()\n",
        "y3_test_np = y3_test.to_numpy()\n",
        "y4_test_np = y4_test.to_numpy()\n",
        "y5_test_np = y5_test.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE_-mt6LBac7"
      },
      "source": [
        "y1_train_np = y1_train.to_numpy()\n",
        "y2_train_np = y2_train.to_numpy()\n",
        "y3_train_np = y3_train.to_numpy()\n",
        "y4_train_np = y4_train.to_numpy()\n",
        "y5_train_np = y5_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "SzajwzokkMdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_np = y1_test.to_numpy()\n",
        "y2_test_np = y2_test.to_numpy()\n",
        "y3_test_np = y3_test.to_numpy()\n",
        "\n",
        "y1_train_np = y1_train.to_numpy()\n",
        "y2_train_np = y2_train.to_numpy()\n",
        "y3_train_np = y3_train.to_numpy()"
      ],
      "metadata": {
        "id": "mdPZQ2HrkP0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rGqxskM-Idq"
      },
      "source": [
        "automl = AutoML()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IopJ7Jf_cb-"
      },
      "source": [
        "automl_settings = {\n",
        "    \"time_budget\": 600,  # in seconds\n",
        "    \"metric\": 'accuracy',\n",
        "    \"task\": 'classification'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ne3jDxpbOfF"
      },
      "source": [
        "### HA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLHEeEQ4_cfQ",
        "outputId": "8995c6d3-fab4-43db-dd47-a025e35f44ee"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x1_train, y_train=y1_train_np,\n",
        "           **automl_settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 11:51:52] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 11:51:52] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 11:51:52] {1963} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-26 11:51:52] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 11:51:52] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 11:51:52] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:53] {2461} INFO - Estimated sufficient time budget=11044s. Estimated necessary time budget=271s.\n",
            "[flaml.automl: 12-26 11:51:53] {2541} INFO -  at 1.6s,\testimator lgbm's best error=0.3789,\tbest estimator lgbm's best error=0.3789\n",
            "[flaml.automl: 12-26 11:51:53] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:54] {2541} INFO -  at 2.7s,\testimator lgbm's best error=0.3789,\tbest estimator lgbm's best error=0.3789\n",
            "[flaml.automl: 12-26 11:51:54] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:56] {2541} INFO -  at 4.7s,\testimator lgbm's best error=0.3618,\tbest estimator lgbm's best error=0.3618\n",
            "[flaml.automl: 12-26 11:51:56] {2347} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-26 11:51:57] {2541} INFO -  at 5.6s,\testimator xgboost's best error=0.3638,\tbest estimator lgbm's best error=0.3618\n",
            "[flaml.automl: 12-26 11:51:57] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:57] {2541} INFO -  at 6.2s,\testimator lgbm's best error=0.3550,\tbest estimator lgbm's best error=0.3550\n",
            "[flaml.automl: 12-26 11:51:58] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:58] {2541} INFO -  at 6.6s,\testimator lgbm's best error=0.3550,\tbest estimator lgbm's best error=0.3550\n",
            "[flaml.automl: 12-26 11:51:58] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:59] {2541} INFO -  at 7.2s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
            "[flaml.automl: 12-26 11:51:59] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:59] {2541} INFO -  at 7.7s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
            "[flaml.automl: 12-26 11:51:59] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 11:51:59] {2541} INFO -  at 8.2s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
            "[flaml.automl: 12-26 11:51:59] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:00] {2541} INFO -  at 9.1s,\testimator lgbm's best error=0.3516,\tbest estimator lgbm's best error=0.3516\n",
            "[flaml.automl: 12-26 11:52:00] {2347} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-26 11:52:01] {2541} INFO -  at 9.5s,\testimator xgboost's best error=0.3638,\tbest estimator lgbm's best error=0.3516\n",
            "[flaml.automl: 12-26 11:52:01] {2347} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-26 11:52:01] {2541} INFO -  at 10.1s,\testimator xgboost's best error=0.3626,\tbest estimator lgbm's best error=0.3516\n",
            "[flaml.automl: 12-26 11:52:01] {2347} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:02] {2541} INFO -  at 10.7s,\testimator lgbm's best error=0.3516,\tbest estimator lgbm's best error=0.3516\n",
            "[flaml.automl: 12-26 11:52:02] {2347} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:05] {2541} INFO -  at 13.3s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:05] {2347} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:52:06] {2541} INFO -  at 14.6s,\testimator extra_tree's best error=0.3888,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:06] {2347} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:23] {2541} INFO -  at 31.4s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:23] {2347} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:52:24] {2541} INFO -  at 32.7s,\testimator extra_tree's best error=0.3743,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:24] {2347} INFO - iteration 17, current learner rf\n",
            "[flaml.automl: 12-26 11:52:25] {2541} INFO -  at 33.9s,\testimator rf's best error=0.3850,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:25] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:28] {2541} INFO -  at 36.2s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:28] {2347} INFO - iteration 19, current learner rf\n",
            "[flaml.automl: 12-26 11:52:29] {2541} INFO -  at 37.5s,\testimator rf's best error=0.3676,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:29] {2347} INFO - iteration 20, current learner rf\n",
            "[flaml.automl: 12-26 11:52:30] {2541} INFO -  at 38.7s,\testimator rf's best error=0.3676,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:30] {2347} INFO - iteration 21, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:52:31] {2541} INFO -  at 40.0s,\testimator extra_tree's best error=0.3743,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:31] {2347} INFO - iteration 22, current learner rf\n",
            "[flaml.automl: 12-26 11:52:33] {2541} INFO -  at 41.5s,\testimator rf's best error=0.3656,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:33] {2347} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-26 11:52:36] {2541} INFO -  at 44.6s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:36] {2347} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:52:37] {2541} INFO -  at 46.2s,\testimator extra_tree's best error=0.3743,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:37] {2347} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:52:39] {2541} INFO -  at 47.4s,\testimator extra_tree's best error=0.3718,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:39] {2347} INFO - iteration 26, current learner catboost\n",
            "[flaml.automl: 12-26 11:52:40] {2541} INFO -  at 49.1s,\testimator catboost's best error=0.3533,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:40] {2347} INFO - iteration 27, current learner catboost\n",
            "[flaml.automl: 12-26 11:52:43] {2541} INFO -  at 51.2s,\testimator catboost's best error=0.3533,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:43] {2347} INFO - iteration 28, current learner catboost\n",
            "[flaml.automl: 12-26 11:52:45] {2541} INFO -  at 54.0s,\testimator catboost's best error=0.3530,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:45] {2347} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-26 11:52:47] {2541} INFO -  at 55.2s,\testimator xgboost's best error=0.3605,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:47] {2347} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-26 11:52:50] {2541} INFO -  at 58.4s,\testimator xgboost's best error=0.3603,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:52:50] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:08] {2541} INFO -  at 76.4s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:08] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:11] {2541} INFO -  at 79.6s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:11] {2347} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:25] {2541} INFO -  at 94.1s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:25] {2347} INFO - iteration 34, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:27] {2541} INFO -  at 95.4s,\testimator extra_tree's best error=0.3718,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:27] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:29] {2541} INFO -  at 97.8s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:29] {2347} INFO - iteration 36, current learner rf\n",
            "[flaml.automl: 12-26 11:53:30] {2541} INFO -  at 99.0s,\testimator rf's best error=0.3602,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:30] {2347} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:32] {2541} INFO -  at 100.2s,\testimator extra_tree's best error=0.3671,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:32] {2347} INFO - iteration 38, current learner rf\n",
            "[flaml.automl: 12-26 11:53:33] {2541} INFO -  at 101.6s,\testimator rf's best error=0.3602,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:33] {2347} INFO - iteration 39, current learner catboost\n",
            "[flaml.automl: 12-26 11:53:35] {2541} INFO -  at 103.2s,\testimator catboost's best error=0.3530,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:35] {2347} INFO - iteration 40, current learner rf\n",
            "[flaml.automl: 12-26 11:53:36] {2541} INFO -  at 104.5s,\testimator rf's best error=0.3602,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:36] {2347} INFO - iteration 41, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:37] {2541} INFO -  at 106.1s,\testimator extra_tree's best error=0.3639,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:37] {2347} INFO - iteration 42, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:39] {2541} INFO -  at 107.3s,\testimator extra_tree's best error=0.3639,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:39] {2347} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:45] {2541} INFO -  at 113.4s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:45] {2347} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:46] {2541} INFO -  at 115.1s,\testimator extra_tree's best error=0.3639,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:46] {2347} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:49] {2541} INFO -  at 117.2s,\testimator extra_tree's best error=0.3599,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:49] {2347} INFO - iteration 46, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:50] {2541} INFO -  at 118.8s,\testimator extra_tree's best error=0.3599,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:50] {2347} INFO - iteration 47, current learner rf\n",
            "[flaml.automl: 12-26 11:53:52] {2541} INFO -  at 120.2s,\testimator rf's best error=0.3593,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:52] {2347} INFO - iteration 48, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:54] {2541} INFO -  at 122.6s,\testimator extra_tree's best error=0.3582,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:54] {2347} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 12-26 11:53:55] {2541} INFO -  at 123.9s,\testimator lgbm's best error=0.3493,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:55] {2347} INFO - iteration 50, current learner catboost\n",
            "[flaml.automl: 12-26 11:53:56] {2541} INFO -  at 124.6s,\testimator catboost's best error=0.3530,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:56] {2347} INFO - iteration 51, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:53:58] {2541} INFO -  at 126.2s,\testimator extra_tree's best error=0.3582,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:58] {2347} INFO - iteration 52, current learner rf\n",
            "[flaml.automl: 12-26 11:53:59] {2541} INFO -  at 127.5s,\testimator rf's best error=0.3593,\tbest estimator lgbm's best error=0.3493\n",
            "[flaml.automl: 12-26 11:53:59] {2347} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-26 11:54:08] {2541} INFO -  at 136.4s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:08] {2347} INFO - iteration 54, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:10] {2541} INFO -  at 138.6s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:10] {2347} INFO - iteration 55, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:12] {2541} INFO -  at 140.5s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:12] {2347} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-26 11:54:26] {2541} INFO -  at 155.0s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:26] {2347} INFO - iteration 57, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:29] {2541} INFO -  at 157.5s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:29] {2347} INFO - iteration 58, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:31] {2541} INFO -  at 159.3s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:31] {2347} INFO - iteration 59, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:33] {2541} INFO -  at 161.7s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:33] {2347} INFO - iteration 60, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:34] {2541} INFO -  at 162.6s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:34] {2347} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl: 12-26 11:54:41] {2541} INFO -  at 169.6s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:41] {2347} INFO - iteration 62, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:46] {2541} INFO -  at 174.3s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:46] {2347} INFO - iteration 63, current learner rf\n",
            "[flaml.automl: 12-26 11:54:47] {2541} INFO -  at 175.7s,\testimator rf's best error=0.3593,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:47] {2347} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:50] {2541} INFO -  at 178.6s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:50] {2347} INFO - iteration 65, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:54:51] {2541} INFO -  at 180.1s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:51] {2347} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl: 12-26 11:54:58] {2541} INFO -  at 186.8s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:54:58] {2347} INFO - iteration 67, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:55:01] {2541} INFO -  at 189.3s,\testimator xgb_limitdepth's best error=0.3534,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:01] {2347} INFO - iteration 68, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:55:02] {2541} INFO -  at 191.2s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:02] {2347} INFO - iteration 69, current learner catboost\n",
            "[flaml.automl: 12-26 11:55:05] {2541} INFO -  at 193.5s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:05] {2347} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl: 12-26 11:55:13] {2541} INFO -  at 201.4s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:13] {2347} INFO - iteration 71, current learner catboost\n",
            "[flaml.automl: 12-26 11:55:14] {2541} INFO -  at 203.1s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:14] {2347} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:55:18] {2541} INFO -  at 206.6s,\testimator extra_tree's best error=0.3558,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:18] {2347} INFO - iteration 73, current learner catboost\n",
            "[flaml.automl: 12-26 11:55:19] {2541} INFO -  at 208.1s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:19] {2347} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:55:21] {2541} INFO -  at 209.4s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:21] {2347} INFO - iteration 75, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:55:24] {2541} INFO -  at 213.0s,\testimator extra_tree's best error=0.3540,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:24] {2347} INFO - iteration 76, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:55:27] {2541} INFO -  at 215.8s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:27] {2347} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl: 12-26 11:55:39] {2541} INFO -  at 227.9s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:39] {2347} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 12-26 11:55:50] {2541} INFO -  at 238.7s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:50] {2347} INFO - iteration 79, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:55:53] {2541} INFO -  at 242.1s,\testimator extra_tree's best error=0.3540,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:53] {2347} INFO - iteration 80, current learner catboost\n",
            "[flaml.automl: 12-26 11:55:55] {2541} INFO -  at 243.7s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:55:55] {2347} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl: 12-26 11:56:16] {2541} INFO -  at 264.9s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:16] {2347} INFO - iteration 82, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:56:17] {2541} INFO -  at 266.0s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:17] {2347} INFO - iteration 83, current learner catboost\n",
            "[flaml.automl: 12-26 11:56:20] {2541} INFO -  at 268.2s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:20] {2347} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:56:21] {2541} INFO -  at 270.1s,\testimator extra_tree's best error=0.3540,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:21] {2347} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:56:28] {2541} INFO -  at 276.8s,\testimator extra_tree's best error=0.3523,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:28] {2347} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:56:31] {2541} INFO -  at 280.0s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:31] {2347} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:56:41] {2541} INFO -  at 289.5s,\testimator extra_tree's best error=0.3518,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:41] {2347} INFO - iteration 88, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:56:47] {2541} INFO -  at 296.0s,\testimator extra_tree's best error=0.3518,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:47] {2347} INFO - iteration 89, current learner rf\n",
            "[flaml.automl: 12-26 11:56:49] {2541} INFO -  at 297.3s,\testimator rf's best error=0.3593,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:49] {2347} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl: 12-26 11:56:52] {2541} INFO -  at 300.7s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:52] {2347} INFO - iteration 91, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:56:53] {2541} INFO -  at 301.9s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:53] {2347} INFO - iteration 92, current learner catboost\n",
            "[flaml.automl: 12-26 11:56:55] {2541} INFO -  at 303.2s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:55] {2347} INFO - iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:56:57] {2541} INFO -  at 306.2s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:57] {2347} INFO - iteration 94, current learner catboost\n",
            "[flaml.automl: 12-26 11:56:59] {2541} INFO -  at 308.0s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:56:59] {2347} INFO - iteration 95, current learner catboost\n",
            "[flaml.automl: 12-26 11:57:01] {2541} INFO -  at 309.7s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:01] {2347} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl: 12-26 11:57:07] {2541} INFO -  at 315.2s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:07] {2347} INFO - iteration 97, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:57:08] {2541} INFO -  at 316.2s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:08] {2347} INFO - iteration 98, current learner rf\n",
            "[flaml.automl: 12-26 11:57:09] {2541} INFO -  at 318.0s,\testimator rf's best error=0.3593,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:09] {2347} INFO - iteration 99, current learner catboost\n",
            "[flaml.automl: 12-26 11:57:12] {2541} INFO -  at 320.7s,\testimator catboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:12] {2347} INFO - iteration 100, current learner lgbm\n",
            "[flaml.automl: 12-26 11:57:31] {2541} INFO -  at 340.1s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:31] {2347} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl: 12-26 11:57:36] {2541} INFO -  at 345.0s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:36] {2347} INFO - iteration 102, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:57:40] {2541} INFO -  at 348.8s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:40] {2347} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 12-26 11:57:41] {2541} INFO -  at 349.4s,\testimator xgboost's best error=0.3597,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:41] {2347} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl: 12-26 11:57:57] {2541} INFO -  at 366.1s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:57] {2347} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 12-26 11:57:58] {2541} INFO -  at 367.0s,\testimator xgboost's best error=0.3543,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:58] {2347} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 12-26 11:57:59] {2541} INFO -  at 367.9s,\testimator xgboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:57:59] {2347} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 12-26 11:58:00] {2541} INFO -  at 368.8s,\testimator xgboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:00] {2347} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 12-26 11:58:01] {2541} INFO -  at 369.7s,\testimator xgboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:01] {2347} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 12-26 11:58:02] {2541} INFO -  at 370.9s,\testimator xgboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:02] {2347} INFO - iteration 110, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:58:13] {2541} INFO -  at 382.0s,\testimator extra_tree's best error=0.3518,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:13] {2347} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 12-26 11:58:14] {2541} INFO -  at 383.0s,\testimator xgboost's best error=0.3516,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:14] {2347} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl: 12-26 11:58:21] {2541} INFO -  at 390.0s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:21] {2347} INFO - iteration 113, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:58:22] {2541} INFO -  at 390.6s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:22] {2347} INFO - iteration 114, current learner xgboost\n",
            "[flaml.automl: 12-26 11:58:23] {2541} INFO -  at 391.9s,\testimator xgboost's best error=0.3511,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:23] {2347} INFO - iteration 115, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:58:29] {2541} INFO -  at 397.5s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:29] {2347} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl: 12-26 11:58:41] {2541} INFO -  at 409.8s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:58:41] {2347} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl: 12-26 11:59:29] {2541} INFO -  at 457.7s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:29] {2347} INFO - iteration 118, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:59:30] {2541} INFO -  at 459.0s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:30] {2347} INFO - iteration 119, current learner xgboost\n",
            "[flaml.automl: 12-26 11:59:31] {2541} INFO -  at 460.0s,\testimator xgboost's best error=0.3511,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:31] {2347} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl: 12-26 11:59:34] {2541} INFO -  at 462.2s,\testimator lgbm's best error=0.3462,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:34] {2347} INFO - iteration 121, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:59:42] {2541} INFO -  at 470.3s,\testimator extra_tree's best error=0.3514,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:42] {2347} INFO - iteration 122, current learner extra_tree\n",
            "[flaml.automl: 12-26 11:59:55] {2541} INFO -  at 483.9s,\testimator extra_tree's best error=0.3501,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:55] {2347} INFO - iteration 123, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 11:59:58] {2541} INFO -  at 486.5s,\testimator xgb_limitdepth's best error=0.3513,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 11:59:58] {2347} INFO - iteration 124, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:00:06] {2541} INFO -  at 494.9s,\testimator extra_tree's best error=0.3501,\tbest estimator lgbm's best error=0.3462\n",
            "[flaml.automl: 12-26 12:00:06] {2347} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl: 12-26 12:00:25] {2541} INFO -  at 513.7s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 12:00:25] {2347} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl: 12-26 12:00:34] {2541} INFO -  at 522.7s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 12:00:34] {2347} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl: 12-26 12:01:51] {2541} INFO -  at 600.0s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 12:01:51] {2347} INFO - iteration 128, current learner lrl1\n",
            "[flaml.automl: 12-26 12:01:52] {2541} INFO -  at 600.5s,\testimator lrl1's best error=0.3841,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 12:01:56] {2753} INFO - retrain lgbm for 4.7s\n",
            "[flaml.automl: 12-26 12:01:56] {2758} INFO - retrained model: LGBMClassifier(colsample_bytree=0.5008105465381789,\n",
            "               learning_rate=0.028770723567839638, max_bin=255,\n",
            "               min_child_samples=6, n_estimators=752, num_leaves=37,\n",
            "               reg_alpha=0.0009765625, reg_lambda=0.038898649078675136,\n",
            "               verbose=-1)\n",
            "[flaml.automl: 12-26 12:01:56] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 12:01:56] {2138} INFO - Time taken to find the best model: 513.7130353450775\n",
            "[flaml.automl: 12-26 12:01:56] {2152} WARNING - Time taken to find the best model is 86% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4vGxHNvw6w4"
      },
      "source": [
        "def create_auc_roc(y1_test_np, automl, x_test):\n",
        "  from sklearn.metrics import roc_curve, roc_auc_score\n",
        "  from matplotlib import pyplot as plt\n",
        "  preds = automl.predict(x_test).reshape(-1, 1)\n",
        "  ns_probs = np.array([0 for _ in range(len(y1_test_np))]).reshape(-1, 1)\n",
        "  print(ns_probs.shape)\n",
        "  ns_auc = roc_auc_score(y1_test_np, ns_probs)\n",
        "  lr_auc = roc_auc_score(y1_test_np, preds)\n",
        "\n",
        "  print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "  print('Trained: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "  ns_fpr, ns_tpr, _ = roc_curve(y1_test_np, ns_probs)\n",
        "  lr_fpr, lr_tpr, _ = roc_curve(y1_test_np, preds)\n",
        "  # plot the roc curve for the model\n",
        "  plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "  plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "  # axis labels\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  # show the legend\n",
        "  plt.legend()\n",
        "  # show the plot\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Z-_l7rlFw61M",
        "outputId": "16062fca-caf0-4a1f-f767-98c9c7940725"
      },
      "source": [
        "create_auc_roc(y1_test_np, automl, x1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11716, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgz4PqHf0LsW",
        "outputId": "8cdb2940-897b-4252-e41c-4c2ad72ef6b9"
      },
      "source": [
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.LGBMEstimator object at 0x7f80121ac7d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLqyp-kq_cjd",
        "outputId": "5fa4a9f7-677d-4fb0-9f32-78a14ba1fa30"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 752, 'num_leaves': 37, 'min_child_samples': 6, 'learning_rate': 0.028770723567839638, 'log_max_bin': 8, 'colsample_bytree': 0.5008105465381789, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.038898649078675136}\n",
            "Best accuracy on validation data: 0.6539\n",
            "Training duration of best run: 4.66 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJO7WAmObQTM"
      },
      "source": [
        "### W/H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7fSu18_coY",
        "outputId": "646efa1d-58ac-4569-ca89-db98c35adb24"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x2_train, y_train=y2_train_np,\n",
        "           **automl_settings)\n",
        "# Export the best model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 12:19:36] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 12:19:36] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 12:19:36] {1963} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-26 12:19:36] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 12:19:36] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 12:19:36] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:39] {2461} INFO - Estimated sufficient time budget=23002s. Estimated necessary time budget=565s.\n",
            "[flaml.automl: 12-26 12:19:39] {2541} INFO -  at 3.0s,\testimator lgbm's best error=0.3983,\tbest estimator lgbm's best error=0.3983\n",
            "[flaml.automl: 12-26 12:19:39] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:40] {2541} INFO -  at 4.1s,\testimator lgbm's best error=0.3983,\tbest estimator lgbm's best error=0.3983\n",
            "[flaml.automl: 12-26 12:19:40] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:42] {2541} INFO -  at 6.8s,\testimator lgbm's best error=0.3500,\tbest estimator lgbm's best error=0.3500\n",
            "[flaml.automl: 12-26 12:19:42] {2347} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-26 12:19:46] {2541} INFO -  at 10.8s,\testimator xgboost's best error=0.3655,\tbest estimator lgbm's best error=0.3500\n",
            "[flaml.automl: 12-26 12:19:46] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:50] {2541} INFO -  at 14.0s,\testimator lgbm's best error=0.2945,\tbest estimator lgbm's best error=0.2945\n",
            "[flaml.automl: 12-26 12:19:50] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:52] {2541} INFO -  at 16.3s,\testimator lgbm's best error=0.2945,\tbest estimator lgbm's best error=0.2945\n",
            "[flaml.automl: 12-26 12:19:52] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:55] {2541} INFO -  at 19.4s,\testimator lgbm's best error=0.2868,\tbest estimator lgbm's best error=0.2868\n",
            "[flaml.automl: 12-26 12:19:55] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 12:19:58] {2541} INFO -  at 22.6s,\testimator lgbm's best error=0.2868,\tbest estimator lgbm's best error=0.2868\n",
            "[flaml.automl: 12-26 12:19:58] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:01] {2541} INFO -  at 25.1s,\testimator lgbm's best error=0.2868,\tbest estimator lgbm's best error=0.2868\n",
            "[flaml.automl: 12-26 12:20:01] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:10] {2541} INFO -  at 34.6s,\testimator lgbm's best error=0.2705,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:10] {2347} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-26 12:20:14] {2541} INFO -  at 38.3s,\testimator xgboost's best error=0.3655,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:14] {2347} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-26 12:20:19] {2541} INFO -  at 43.5s,\testimator xgboost's best error=0.3471,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:19] {2347} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:20:21] {2541} INFO -  at 44.9s,\testimator extra_tree's best error=0.3709,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:21] {2347} INFO - iteration 13, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:20:22] {2541} INFO -  at 46.3s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:22] {2347} INFO - iteration 14, current learner rf\n",
            "[flaml.automl: 12-26 12:20:23] {2541} INFO -  at 47.7s,\testimator rf's best error=0.3639,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:23] {2347} INFO - iteration 15, current learner rf\n",
            "[flaml.automl: 12-26 12:20:25] {2541} INFO -  at 49.1s,\testimator rf's best error=0.3419,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:25] {2347} INFO - iteration 16, current learner rf\n",
            "[flaml.automl: 12-26 12:20:26] {2541} INFO -  at 50.9s,\testimator rf's best error=0.3419,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:26] {2347} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:20:28] {2541} INFO -  at 52.3s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:28] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:29] {2541} INFO -  at 53.2s,\testimator lgbm's best error=0.2705,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:29] {2347} INFO - iteration 19, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:20:30] {2541} INFO -  at 54.9s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:30] {2347} INFO - iteration 20, current learner rf\n",
            "[flaml.automl: 12-26 12:20:32] {2541} INFO -  at 56.3s,\testimator rf's best error=0.3400,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:32] {2347} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-26 12:20:33] {2541} INFO -  at 57.2s,\testimator xgboost's best error=0.3313,\tbest estimator lgbm's best error=0.2705\n",
            "[flaml.automl: 12-26 12:20:33] {2347} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:37] {2541} INFO -  at 61.8s,\testimator lgbm's best error=0.2392,\tbest estimator lgbm's best error=0.2392\n",
            "[flaml.automl: 12-26 12:20:37] {2347} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:45] {2541} INFO -  at 69.2s,\testimator lgbm's best error=0.2324,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:20:45] {2347} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-26 12:20:46] {2541} INFO -  at 70.1s,\testimator xgboost's best error=0.3272,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:20:46] {2347} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:20:47] {2541} INFO -  at 71.5s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:20:47] {2347} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:52] {2541} INFO -  at 76.0s,\testimator lgbm's best error=0.2324,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:20:52] {2347} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl: 12-26 12:20:59] {2541} INFO -  at 83.4s,\testimator lgbm's best error=0.2324,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:20:59] {2347} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:21:01] {2541} INFO -  at 85.1s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:21:01] {2347} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:21:02] {2541} INFO -  at 86.4s,\testimator extra_tree's best error=0.3358,\tbest estimator lgbm's best error=0.2324\n",
            "[flaml.automl: 12-26 12:21:02] {2347} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:10] {2541} INFO -  at 94.0s,\testimator lgbm's best error=0.2057,\tbest estimator lgbm's best error=0.2057\n",
            "[flaml.automl: 12-26 12:21:10] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:20] {2541} INFO -  at 104.3s,\testimator lgbm's best error=0.2057,\tbest estimator lgbm's best error=0.2057\n",
            "[flaml.automl: 12-26 12:21:20] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:27] {2541} INFO -  at 111.3s,\testimator lgbm's best error=0.2057,\tbest estimator lgbm's best error=0.2057\n",
            "[flaml.automl: 12-26 12:21:27] {2347} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:21:29] {2541} INFO -  at 113.5s,\testimator extra_tree's best error=0.3234,\tbest estimator lgbm's best error=0.2057\n",
            "[flaml.automl: 12-26 12:21:29] {2347} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:38] {2541} INFO -  at 122.0s,\testimator lgbm's best error=0.1847,\tbest estimator lgbm's best error=0.1847\n",
            "[flaml.automl: 12-26 12:21:38] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:45] {2541} INFO -  at 129.7s,\testimator lgbm's best error=0.1847,\tbest estimator lgbm's best error=0.1847\n",
            "[flaml.automl: 12-26 12:21:45] {2347} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:21:47] {2541} INFO -  at 131.0s,\testimator extra_tree's best error=0.3234,\tbest estimator lgbm's best error=0.1847\n",
            "[flaml.automl: 12-26 12:21:47] {2347} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl: 12-26 12:21:49] {2541} INFO -  at 133.7s,\testimator lgbm's best error=0.1847,\tbest estimator lgbm's best error=0.1847\n",
            "[flaml.automl: 12-26 12:21:49] {2347} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-26 12:21:50] {2541} INFO -  at 134.7s,\testimator xgboost's best error=0.3272,\tbest estimator lgbm's best error=0.1847\n",
            "[flaml.automl: 12-26 12:21:50] {2347} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl: 12-26 12:22:30] {2541} INFO -  at 174.9s,\testimator lgbm's best error=0.1678,\tbest estimator lgbm's best error=0.1678\n",
            "[flaml.automl: 12-26 12:22:30] {2347} INFO - iteration 40, current learner catboost\n",
            "[flaml.automl: 12-26 12:22:42] {2541} INFO -  at 186.4s,\testimator catboost's best error=0.2462,\tbest estimator lgbm's best error=0.1678\n",
            "[flaml.automl: 12-26 12:22:42] {2347} INFO - iteration 41, current learner catboost\n",
            "[flaml.automl: 12-26 12:23:00] {2541} INFO -  at 204.6s,\testimator catboost's best error=0.2459,\tbest estimator lgbm's best error=0.1678\n",
            "[flaml.automl: 12-26 12:23:00] {2347} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 12-26 12:23:02] {2541} INFO -  at 206.4s,\testimator xgboost's best error=0.2843,\tbest estimator lgbm's best error=0.1678\n",
            "[flaml.automl: 12-26 12:23:02] {2347} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 12-26 12:23:42] {2541} INFO -  at 246.2s,\testimator lgbm's best error=0.1676,\tbest estimator lgbm's best error=0.1676\n",
            "[flaml.automl: 12-26 12:23:42] {2347} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 12-26 12:23:44] {2541} INFO -  at 248.8s,\testimator xgboost's best error=0.2748,\tbest estimator lgbm's best error=0.1676\n",
            "[flaml.automl: 12-26 12:23:44] {2347} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:23:47] {2541} INFO -  at 250.9s,\testimator extra_tree's best error=0.3234,\tbest estimator lgbm's best error=0.1676\n",
            "[flaml.automl: 12-26 12:23:47] {2347} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 12-26 12:23:48] {2541} INFO -  at 252.7s,\testimator xgboost's best error=0.2748,\tbest estimator lgbm's best error=0.1676\n",
            "[flaml.automl: 12-26 12:23:48] {2347} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 12-26 12:24:26] {2541} INFO -  at 290.8s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:24:26] {2347} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 12-26 12:24:29] {2541} INFO -  at 293.0s,\testimator xgboost's best error=0.2671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:24:29] {2347} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 12-26 12:24:50] {2541} INFO -  at 314.6s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:24:50] {2347} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 12-26 12:25:19] {2541} INFO -  at 343.1s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:25:19] {2347} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-26 12:25:21] {2541} INFO -  at 345.3s,\testimator xgboost's best error=0.2671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:25:21] {2347} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-26 12:27:39] {2541} INFO -  at 483.3s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:27:39] {2347} INFO - iteration 53, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:27:43] {2541} INFO -  at 487.2s,\testimator xgb_limitdepth's best error=0.2776,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:27:43] {2347} INFO - iteration 54, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:27:46] {2541} INFO -  at 490.2s,\testimator xgb_limitdepth's best error=0.2776,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:27:46] {2347} INFO - iteration 55, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:27:50] {2541} INFO -  at 494.1s,\testimator xgb_limitdepth's best error=0.2667,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:27:50] {2347} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-26 12:28:08] {2541} INFO -  at 511.9s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:28:08] {2347} INFO - iteration 57, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:28:11] {2541} INFO -  at 515.1s,\testimator xgb_limitdepth's best error=0.2667,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:28:11] {2347} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 12-26 12:29:53] {2541} INFO -  at 617.5s,\testimator lgbm's best error=0.1671,\tbest estimator lgbm's best error=0.1671\n",
            "[flaml.automl: 12-26 12:30:01] {2753} INFO - retrain lgbm for 7.9s\n",
            "[flaml.automl: 12-26 12:30:01] {2758} INFO - retrained model: LGBMClassifier(colsample_bytree=0.4676132458366714,\n",
            "               learning_rate=0.11621588299658563, max_bin=511,\n",
            "               min_child_samples=5, n_estimators=186, num_leaves=1099,\n",
            "               reg_alpha=0.0024686655398856224,\n",
            "               reg_lambda=0.0028201449346997825, verbose=-1)\n",
            "[flaml.automl: 12-26 12:30:01] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 12:30:01] {2138} INFO - Time taken to find the best model: 290.7865643501282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "qiTD3guQ0NGl",
        "outputId": "0902b898-f3e2-4491-e8d1-8d7a1a22884b"
      },
      "source": [
        "create_auc_roc(y2_test_np, automl, x2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18250, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.846\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmItSSa12DDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b398d0-cbff-4e92-dd3f-279d467fe708"
      },
      "source": [
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.LGBMEstimator object at 0x7f8005e30e90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWIWpD6i_cue",
        "outputId": "48e582d3-ff8f-4727-dae7-362cd1836337"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 186, 'num_leaves': 1099, 'min_child_samples': 5, 'learning_rate': 0.11621588299658563, 'log_max_bin': 9, 'colsample_bytree': 0.4676132458366714, 'reg_alpha': 0.0024686655398856224, 'reg_lambda': 0.0028201449346997825}\n",
            "Best accuracy on validation data: 0.8329\n",
            "Training duration of best run: 7.904 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU8JMc9oIsZf"
      },
      "source": [
        "### HAWH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD7w8YzaItrw",
        "outputId": "e0dd8f04-344a-4ef3-ad3e-b638ffc5cd54"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x3_train, y_train=y3_train_np,\n",
        "           **automl_settings)\n",
        "# print(automl.predict_proba(X_train).shape)\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 12:46:58] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 12:46:58] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 12:46:58] {1963} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-26 12:46:58] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 12:46:58] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 12:46:58] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:01] {2461} INFO - Estimated sufficient time budget=22996s. Estimated necessary time budget=565s.\n",
            "[flaml.automl: 12-26 12:47:01] {2541} INFO -  at 3.1s,\testimator lgbm's best error=0.3175,\tbest estimator lgbm's best error=0.3175\n",
            "[flaml.automl: 12-26 12:47:01] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:01] {2541} INFO -  at 3.9s,\testimator lgbm's best error=0.3175,\tbest estimator lgbm's best error=0.3175\n",
            "[flaml.automl: 12-26 12:47:01] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:02] {2541} INFO -  at 4.7s,\testimator lgbm's best error=0.3052,\tbest estimator lgbm's best error=0.3052\n",
            "[flaml.automl: 12-26 12:47:02] {2347} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:03] {2541} INFO -  at 5.7s,\testimator lgbm's best error=0.2256,\tbest estimator lgbm's best error=0.2256\n",
            "[flaml.automl: 12-26 12:47:03] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:04] {2541} INFO -  at 6.6s,\testimator lgbm's best error=0.2256,\tbest estimator lgbm's best error=0.2256\n",
            "[flaml.automl: 12-26 12:47:04] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:05] {2541} INFO -  at 7.6s,\testimator lgbm's best error=0.2196,\tbest estimator lgbm's best error=0.2196\n",
            "[flaml.automl: 12-26 12:47:05] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:06] {2541} INFO -  at 8.6s,\testimator lgbm's best error=0.2196,\tbest estimator lgbm's best error=0.2196\n",
            "[flaml.automl: 12-26 12:47:06] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:07] {2541} INFO -  at 9.4s,\testimator lgbm's best error=0.2196,\tbest estimator lgbm's best error=0.2196\n",
            "[flaml.automl: 12-26 12:47:07] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:09] {2541} INFO -  at 11.2s,\testimator lgbm's best error=0.1996,\tbest estimator lgbm's best error=0.1996\n",
            "[flaml.automl: 12-26 12:47:09] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:10] {2541} INFO -  at 12.2s,\testimator lgbm's best error=0.1996,\tbest estimator lgbm's best error=0.1996\n",
            "[flaml.automl: 12-26 12:47:10] {2347} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:15] {2541} INFO -  at 17.4s,\testimator lgbm's best error=0.1437,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:15] {2347} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-26 12:47:16] {2541} INFO -  at 18.5s,\testimator xgboost's best error=0.3175,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:16] {2347} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 12-26 12:47:17] {2541} INFO -  at 19.3s,\testimator xgboost's best error=0.3175,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:17] {2347} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-26 12:47:18] {2541} INFO -  at 20.3s,\testimator xgboost's best error=0.3068,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:18] {2347} INFO - iteration 14, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:47:19] {2541} INFO -  at 21.6s,\testimator extra_tree's best error=0.3235,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:19] {2347} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-26 12:47:20] {2541} INFO -  at 22.6s,\testimator xgboost's best error=0.2712,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:20] {2347} INFO - iteration 16, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:47:21] {2541} INFO -  at 23.9s,\testimator extra_tree's best error=0.2996,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:21] {2347} INFO - iteration 17, current learner rf\n",
            "[flaml.automl: 12-26 12:47:23] {2541} INFO -  at 25.2s,\testimator rf's best error=0.3233,\tbest estimator lgbm's best error=0.1437\n",
            "[flaml.automl: 12-26 12:47:23] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:31] {2541} INFO -  at 33.8s,\testimator lgbm's best error=0.1216,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:31] {2347} INFO - iteration 19, current learner rf\n",
            "[flaml.automl: 12-26 12:47:33] {2541} INFO -  at 35.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:33] {2347} INFO - iteration 20, current learner rf\n",
            "[flaml.automl: 12-26 12:47:34] {2541} INFO -  at 36.8s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:34] {2347} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-26 12:47:35] {2541} INFO -  at 38.0s,\testimator xgboost's best error=0.2712,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:35] {2347} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:41] {2541} INFO -  at 43.3s,\testimator lgbm's best error=0.1216,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:41] {2347} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-26 12:47:49] {2541} INFO -  at 51.7s,\testimator lgbm's best error=0.1216,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:49] {2347} INFO - iteration 24, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:47:51] {2541} INFO -  at 53.1s,\testimator extra_tree's best error=0.2996,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:51] {2347} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:47:53] {2541} INFO -  at 55.1s,\testimator extra_tree's best error=0.2945,\tbest estimator lgbm's best error=0.1216\n",
            "[flaml.automl: 12-26 12:47:53] {2347} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:02] {2541} INFO -  at 64.5s,\testimator lgbm's best error=0.0882,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:02] {2347} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-26 12:48:03] {2541} INFO -  at 65.7s,\testimator xgboost's best error=0.2712,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:03] {2347} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-26 12:48:05] {2541} INFO -  at 67.4s,\testimator xgboost's best error=0.2248,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:05] {2347} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-26 12:48:07] {2541} INFO -  at 69.6s,\testimator xgboost's best error=0.2103,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:07] {2347} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:16] {2541} INFO -  at 79.0s,\testimator lgbm's best error=0.0882,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:16] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:25] {2541} INFO -  at 87.2s,\testimator lgbm's best error=0.0882,\tbest estimator lgbm's best error=0.0882\n",
            "[flaml.automl: 12-26 12:48:25] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:34] {2541} INFO -  at 96.9s,\testimator lgbm's best error=0.0742,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:34] {2347} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 12-26 12:48:36] {2541} INFO -  at 98.5s,\testimator xgboost's best error=0.2103,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:36] {2347} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:45] {2541} INFO -  at 107.3s,\testimator lgbm's best error=0.0742,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:45] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 12:48:48] {2541} INFO -  at 110.3s,\testimator lgbm's best error=0.0742,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:48] {2347} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:48:49] {2541} INFO -  at 111.6s,\testimator extra_tree's best error=0.2945,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:49] {2347} INFO - iteration 37, current learner rf\n",
            "[flaml.automl: 12-26 12:48:51] {2541} INFO -  at 113.1s,\testimator rf's best error=0.2870,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:51] {2347} INFO - iteration 38, current learner rf\n",
            "[flaml.automl: 12-26 12:48:52] {2541} INFO -  at 114.4s,\testimator rf's best error=0.2870,\tbest estimator lgbm's best error=0.0742\n",
            "[flaml.automl: 12-26 12:48:52] {2347} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl: 12-26 12:49:32] {2541} INFO -  at 154.4s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:49:32] {2347} INFO - iteration 40, current learner catboost\n",
            "[flaml.automl: 12-26 12:50:15] {2541} INFO -  at 197.3s,\testimator catboost's best error=0.1184,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:50:15] {2347} INFO - iteration 41, current learner catboost\n",
            "[flaml.automl: 12-26 12:51:30] {2541} INFO -  at 272.6s,\testimator catboost's best error=0.1159,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:51:30] {2347} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 12-26 12:51:32] {2541} INFO -  at 274.4s,\testimator xgboost's best error=0.1888,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:51:32] {2347} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 12-26 12:52:16] {2541} INFO -  at 318.1s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:52:16] {2347} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 12-26 12:52:18] {2541} INFO -  at 320.2s,\testimator xgboost's best error=0.1888,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:52:18] {2347} INFO - iteration 45, current learner extra_tree\n",
            "[flaml.automl: 12-26 12:52:20] {2541} INFO -  at 322.2s,\testimator extra_tree's best error=0.2945,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:52:20] {2347} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 12-26 12:52:21] {2541} INFO -  at 323.8s,\testimator xgboost's best error=0.1888,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:52:21] {2347} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 12-26 12:53:02] {2541} INFO -  at 364.5s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:53:02] {2347} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 12-26 12:53:05] {2541} INFO -  at 367.6s,\testimator xgboost's best error=0.1703,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:53:05] {2347} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 12-26 12:53:29] {2541} INFO -  at 391.3s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:53:29] {2347} INFO - iteration 50, current learner rf\n",
            "[flaml.automl: 12-26 12:53:31] {2541} INFO -  at 393.5s,\testimator rf's best error=0.2870,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:53:31] {2347} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-26 12:53:34] {2541} INFO -  at 396.0s,\testimator xgboost's best error=0.1703,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:53:34] {2347} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-26 12:54:05] {2541} INFO -  at 427.4s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:54:05] {2347} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-26 12:56:22] {2541} INFO -  at 565.0s,\testimator lgbm's best error=0.0651,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:22] {2347} INFO - iteration 54, current learner rf\n",
            "[flaml.automl: 12-26 12:56:24] {2541} INFO -  at 566.2s,\testimator rf's best error=0.2812,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:24] {2347} INFO - iteration 55, current learner rf\n",
            "[flaml.automl: 12-26 12:56:26] {2541} INFO -  at 568.4s,\testimator rf's best error=0.2542,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:26] {2347} INFO - iteration 56, current learner rf\n",
            "[flaml.automl: 12-26 12:56:27] {2541} INFO -  at 569.6s,\testimator rf's best error=0.2542,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:27] {2347} INFO - iteration 57, current learner rf\n",
            "[flaml.automl: 12-26 12:56:29] {2541} INFO -  at 571.6s,\testimator rf's best error=0.2542,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:29] {2347} INFO - iteration 58, current learner rf\n",
            "[flaml.automl: 12-26 12:56:31] {2541} INFO -  at 573.7s,\testimator rf's best error=0.2236,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:31] {2347} INFO - iteration 59, current learner rf\n",
            "[flaml.automl: 12-26 12:56:33] {2541} INFO -  at 575.1s,\testimator rf's best error=0.2236,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:33] {2347} INFO - iteration 60, current learner rf\n",
            "[flaml.automl: 12-26 12:56:35] {2541} INFO -  at 577.5s,\testimator rf's best error=0.2049,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:35] {2347} INFO - iteration 61, current learner rf\n",
            "[flaml.automl: 12-26 12:56:37] {2541} INFO -  at 579.6s,\testimator rf's best error=0.2003,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:37] {2347} INFO - iteration 62, current learner rf\n",
            "[flaml.automl: 12-26 12:56:40] {2541} INFO -  at 582.0s,\testimator rf's best error=0.2003,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:40] {2347} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-26 12:56:45] {2541} INFO -  at 587.8s,\testimator xgboost's best error=0.1703,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:45] {2347} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:56:49] {2541} INFO -  at 591.6s,\testimator xgb_limitdepth's best error=0.2018,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:49] {2347} INFO - iteration 65, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:56:53] {2541} INFO -  at 595.1s,\testimator xgb_limitdepth's best error=0.2018,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:53] {2347} INFO - iteration 66, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 12:56:56] {2541} INFO -  at 598.2s,\testimator xgb_limitdepth's best error=0.1963,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:56:56] {2347} INFO - iteration 67, current learner lrl1\n",
            "[flaml.automl: 12-26 12:56:59] {2541} INFO -  at 601.4s,\testimator lrl1's best error=0.2419,\tbest estimator lgbm's best error=0.0651\n",
            "[flaml.automl: 12-26 12:57:07] {2753} INFO - retrain lgbm for 8.4s\n",
            "[flaml.automl: 12-26 12:57:07] {2758} INFO - retrained model: LGBMClassifier(colsample_bytree=0.4676132458366714,\n",
            "               learning_rate=0.11621588299658571, max_bin=511,\n",
            "               min_child_samples=2, n_estimators=186, num_leaves=1099,\n",
            "               reg_alpha=0.002468665539885623, reg_lambda=0.0028201449346997825,\n",
            "               verbose=-1)\n",
            "[flaml.automl: 12-26 12:57:07] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 12:57:07] {2138} INFO - Time taken to find the best model: 154.39581274986267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.LGBMEstimator object at 0x7f800502da10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Qt9lppI4_s",
        "outputId": "4be3ed3a-9555-4241-a4ea-ebfd8d796ddc"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 186, 'num_leaves': 1099, 'min_child_samples': 2, 'learning_rate': 0.11621588299658571, 'log_max_bin': 9, 'colsample_bytree': 0.4676132458366714, 'reg_alpha': 0.002468665539885623, 'reg_lambda': 0.0028201449346997825}\n",
            "Best accuracy on validation data: 0.9349\n",
            "Training duration of best run: 8.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wDW2sAkI4Bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "bf78be95-2215-4c10-a6f9-abf89118b5aa"
      },
      "source": [
        "create_auc_roc(y3_test_np, automl, x3_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20848, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.940\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAINnWbPlnoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15-16 Dataset"
      ],
      "metadata": {
        "id": "mpuSjkGv4L1E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV11oOLy4L1g"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using balanced datasets independently"
      ],
      "metadata": {
        "id": "xaJ9HNiL4L1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('15-16_Balanced_Stunting.csv')\n",
        "df2 = pd.read_csv('15-16_Balanced_Wasting.csv')\n",
        "df3 = pd.read_csv('15-16_Balanced_Stunted_Wasting.csv')\n",
        "df1 = df1.drop(['Unnamed: 0'], axis =1)\n",
        "df2 = df2.drop(['Unnamed: 0'], axis = 1)\n",
        "df3 = df3.drop(['Unnamed: 0'], axis =1)"
      ],
      "metadata": {
        "id": "NlXm7zwR4L1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "4b3fa241-c73a-425d-eb36-6a60bf7631bf",
        "id": "Efqfjjzu4L1i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d7a1cb0-9f18-42ee-a037-45436fb8a42e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Area</th>\n",
              "      <th>Religion</th>\n",
              "      <th>caste</th>\n",
              "      <th>mothers education</th>\n",
              "      <th>source of water</th>\n",
              "      <th>toilet facility</th>\n",
              "      <th>no of members</th>\n",
              "      <th>no of living children</th>\n",
              "      <th>mothers age(at first birth)</th>\n",
              "      <th>sex of household head</th>\n",
              "      <th>wealth index</th>\n",
              "      <th>initiaion of bf</th>\n",
              "      <th>sex of child</th>\n",
              "      <th>months of bf</th>\n",
              "      <th>mothers bmi</th>\n",
              "      <th>child's age</th>\n",
              "      <th>index to birth history</th>\n",
              "      <th>birth weight</th>\n",
              "      <th>history of illness</th>\n",
              "      <th>Exposure to mass media</th>\n",
              "      <th>dietary score</th>\n",
              "      <th>immunization</th>\n",
              "      <th>H/A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226310</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226311</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226312</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226313</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226314</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>226315 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d7a1cb0-9f18-42ee-a037-45436fb8a42e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d7a1cb0-9f18-42ee-a037-45436fb8a42e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d7a1cb0-9f18-42ee-a037-45436fb8a42e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        State  Area  Religion  ...  dietary score  immunization  H/A\n",
              "0           1     1         1  ...              0             0    0\n",
              "1           1     1         1  ...              0             0    0\n",
              "2           1     0         0  ...              4             2    0\n",
              "3           1     0         0  ...              3             2    0\n",
              "4           1     0         0  ...              0             2    0\n",
              "...       ...   ...       ...  ...            ...           ...  ...\n",
              "226310      4     0         2  ...              0             0    1\n",
              "226311      4     0         0  ...              0             0    1\n",
              "226312      4     0         1  ...              0             0    1\n",
              "226313      3     1         2  ...              3             1    1\n",
              "226314      4     0         1  ...              0             0    1\n",
              "\n",
              "[226315 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df1.drop(['H/A'], axis = 1)\n",
        "x2 = df2.drop(['W/H'], axis = 1)\n",
        "x3 = df3.drop(['HAWH'], axis = 1)"
      ],
      "metadata": {
        "id": "Xk0e7WiB4L1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = df1['H/A']\n",
        "y2 = df2['W/H']\n",
        "y3 = df3['HAWH']"
      ],
      "metadata": {
        "id": "dmmoce_34L1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.3, random_state=96, stratify = y1)\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.3, random_state=103, stratify = y2)\n",
        "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.3, random_state=48, stratify = y3)"
      ],
      "metadata": {
        "id": "zsdhu0C34L1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using unbalanced dependent datasets"
      ],
      "metadata": {
        "id": "RHEfqQC64L1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('New_Dataset_5-6.csv')"
      ],
      "metadata": {
        "id": "-VCu5v-j4L1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "outputId": "ddd8b4c5-f914-4c9b-eff0-2aaa676ec821",
        "id": "s3gjAlgM4L1n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b39b531e-3b71-4b78-ba4f-481c5e2f3c12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>state</th>\n",
              "      <th>area</th>\n",
              "      <th>religion</th>\n",
              "      <th>caste</th>\n",
              "      <th>type of family</th>\n",
              "      <th>father's education</th>\n",
              "      <th>father's occupation</th>\n",
              "      <th>mother's education</th>\n",
              "      <th>mother's occupation</th>\n",
              "      <th>total family members</th>\n",
              "      <th>exposure to mass media</th>\n",
              "      <th>Source of drinking water</th>\n",
              "      <th>Toilet Facility</th>\n",
              "      <th>mother's age</th>\n",
              "      <th>mother's bmi</th>\n",
              "      <th>child's age</th>\n",
              "      <th>sex of child</th>\n",
              "      <th>birth weight</th>\n",
              "      <th>initiation of bf(early initiation)</th>\n",
              "      <th>wealth index</th>\n",
              "      <th>months of bf</th>\n",
              "      <th>history of illness</th>\n",
              "      <th>immunization</th>\n",
              "      <th>index to birth history</th>\n",
              "      <th>no of living children</th>\n",
              "      <th>sex of household head</th>\n",
              "      <th>dietary score</th>\n",
              "      <th>H/A</th>\n",
              "      <th>W/A</th>\n",
              "      <th>W/H</th>\n",
              "      <th>Bmi</th>\n",
              "      <th>HAWH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>OBC</td>\n",
              "      <td>2</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>underweight</td>\n",
              "      <td>24-36</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Muslim</td>\n",
              "      <td>OBC</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>No education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>7</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>6-12</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>18-24</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>South_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Christian</td>\n",
              "      <td>SC</td>\n",
              "      <td>2</td>\n",
              "      <td>No education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>No education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>9</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>6-</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Partially immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38054</th>\n",
              "      <td>38054</td>\n",
              "      <td>51550</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>No education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>underweight</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorest</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>1</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38055</th>\n",
              "      <td>38055</td>\n",
              "      <td>51551</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>1</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>skilled labour</td>\n",
              "      <td>Primary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>underweight</td>\n",
              "      <td>48-59</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not Measured</td>\n",
              "      <td>Late initiation</td>\n",
              "      <td>Poorest</td>\n",
              "      <td>&lt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38056</th>\n",
              "      <td>38056</td>\n",
              "      <td>51552</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Unimproved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>24-36</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.5+</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Poorer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38057</th>\n",
              "      <td>38057</td>\n",
              "      <td>51553</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>Rgri</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>7</td>\n",
              "      <td>No</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>&lt;20</td>\n",
              "      <td>healthy</td>\n",
              "      <td>36-48</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.5+</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Middle</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38058</th>\n",
              "      <td>38058</td>\n",
              "      <td>51554</td>\n",
              "      <td>East_India</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Hindu</td>\n",
              "      <td>Others</td>\n",
              "      <td>2</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>sales</td>\n",
              "      <td>Secondary education</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Improved</td>\n",
              "      <td>Improved</td>\n",
              "      <td>20-29</td>\n",
              "      <td>healthy</td>\n",
              "      <td>36-48</td>\n",
              "      <td>Female</td>\n",
              "      <td>2.5-</td>\n",
              "      <td>Early initiation</td>\n",
              "      <td>Richer</td>\n",
              "      <td>&gt;24</td>\n",
              "      <td>0</td>\n",
              "      <td>Fully immunized</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38059 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b39b531e-3b71-4b78-ba4f-481c5e2f3c12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b39b531e-3b71-4b78-ba4f-481c5e2f3c12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b39b531e-3b71-4b78-ba4f-481c5e2f3c12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1        state   area  ... W/A W/H  Bmi HAWH\n",
              "0               0             0  South_India  Rural  ...   1   1    0    1\n",
              "1               1             1  South_India  Rural  ...   0   0    0    0\n",
              "2               2             2  South_India  Rural  ...   0   0    0    0\n",
              "3               3             3  South_India  Rural  ...   0   0    0    0\n",
              "4               4             6  South_India  Rural  ...   0   0    0    0\n",
              "...           ...           ...          ...    ...  ...  ..  ..  ...  ...\n",
              "38054       38054         51550   East_India  Rural  ...   1   0    0    0\n",
              "38055       38055         51551   East_India  Rural  ...   1   0    0    0\n",
              "38056       38056         51552   East_India  Rural  ...   1   0    0    0\n",
              "38057       38057         51553   East_India  Rural  ...   0   0    0    0\n",
              "38058       38058         51554   East_India  Rural  ...   0   0    0    0\n",
              "\n",
              "[38059 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyk3gPkd4L1o"
      },
      "source": [
        "def split_X_y(data):\n",
        "  X = data.drop('H/A',axis = 1)\n",
        "  X = X.drop('W/A',axis = 1)\n",
        "  X = X.drop('W/H',axis = 1)\n",
        "  X = X.drop('Bmi',axis = 1)\n",
        "  X = X.drop('HAWH', axis = 1)\n",
        "  y1 = data['W/A']\n",
        "  y2 = data['H/A']\n",
        "  y3 = data['W/H']\n",
        "  y4 = data['Bmi']\n",
        "  y5 = data['HAWH']\n",
        "  y1 = y1.to_frame()  # convert y outputs from series to dataframe\n",
        "  y2 = y2.to_frame()\n",
        "  y3 = y3.to_frame()\n",
        "  y4 = y4.to_frame()\n",
        "  y5 = y5.to_frame()\n",
        "  print(X.shape, 'X shape')\n",
        "  print(y1.shape, 'y1 shape')\n",
        "  print(y2.shape, 'y2 shape')\n",
        "  print(y3.shape, 'y3 shape')\n",
        "  print(y4.shape, 'y4 shape')\n",
        "  print(y5.shape, 'y5 shape')\n",
        "  return X, y1, y2, y3, y4, y5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCpgqjDy4L1p"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.25, random_state = 456)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d14e3c8-0568-4306-a652-b8bde9162710",
        "id": "twWHpjVK4L1q"
      },
      "source": [
        "X_train, y1_train, y2_train, y3_train, y4_train, y5_train = split_X_y(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28544, 29) X shape\n",
            "(28544, 1) y1 shape\n",
            "(28544, 1) y2 shape\n",
            "(28544, 1) y3 shape\n",
            "(28544, 1) y4 shape\n",
            "(28544, 1) y5 shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62341ce-08aa-410e-cd73-f1a50f03970b",
        "id": "6ylxdaG54L1r"
      },
      "source": [
        "X_test, y1_test, y2_test, y3_test, y4_test, y5_test= split_X_y(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9515, 29) X shape\n",
            "(9515, 1) y1 shape\n",
            "(9515, 1) y2 shape\n",
            "(9515, 1) y3 shape\n",
            "(9515, 1) y4 shape\n",
            "(9515, 1) y5 shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MeKzeTS4L1s"
      },
      "source": [
        "y1_test_np = y1_test.to_numpy()\n",
        "y2_test_np = y2_test.to_numpy()\n",
        "y3_test_np = y3_test.to_numpy()\n",
        "y4_test_np = y4_test.to_numpy()\n",
        "y5_test_np = y5_test.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoys2ALU4L1s"
      },
      "source": [
        "y1_train_np = y1_train.to_numpy()\n",
        "y2_train_np = y2_train.to_numpy()\n",
        "y3_train_np = y3_train.to_numpy()\n",
        "y4_train_np = y4_train.to_numpy()\n",
        "y5_train_np = y5_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model"
      ],
      "metadata": {
        "id": "yJAcBCd-4L1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1_test_np = y1_test.to_numpy()\n",
        "y2_test_np = y2_test.to_numpy()\n",
        "y3_test_np = y3_test.to_numpy()\n",
        "\n",
        "y1_train_np = y1_train.to_numpy()\n",
        "y2_train_np = y2_train.to_numpy()\n",
        "y3_train_np = y3_train.to_numpy()"
      ],
      "metadata": {
        "id": "qzPMxzQX4L1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XosWmZOB4L1v"
      },
      "source": [
        "automl = AutoML()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZadfvUBH4L1v"
      },
      "source": [
        "automl_settings = {\n",
        "    \"time_budget\": 600,  # in seconds\n",
        "    \"metric\": 'accuracy',\n",
        "    \"task\": 'classification'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LleKyP204L1v"
      },
      "source": [
        "### HA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e705af5-b1d3-454a-fc57-050dbec02696",
        "id": "eZ1JlLAd4L1w"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x1_train, y_train=y1_train_np,\n",
        "           **automl_settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 13:27:14] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 13:27:14] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 13:27:14] {1963} INFO - Evaluation method: holdout\n",
            "[flaml.automl: 12-26 13:27:14] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 13:27:14] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:14] {2461} INFO - Estimated sufficient time budget=6886s. Estimated necessary time budget=169s.\n",
            "[flaml.automl: 12-26 13:27:14] {2541} INFO -  at 1.4s,\testimator lgbm's best error=0.3931,\tbest estimator lgbm's best error=0.3931\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:14] {2541} INFO -  at 1.5s,\testimator lgbm's best error=0.3931,\tbest estimator lgbm's best error=0.3931\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:14] {2541} INFO -  at 1.5s,\testimator lgbm's best error=0.3788,\tbest estimator lgbm's best error=0.3788\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:14] {2541} INFO -  at 1.6s,\testimator xgboost's best error=0.3818,\tbest estimator lgbm's best error=0.3788\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:14] {2541} INFO -  at 1.7s,\testimator lgbm's best error=0.3608,\tbest estimator lgbm's best error=0.3608\n",
            "[flaml.automl: 12-26 13:27:14] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 1.7s,\testimator lgbm's best error=0.3608,\tbest estimator lgbm's best error=0.3608\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 1.8s,\testimator lgbm's best error=0.3604,\tbest estimator lgbm's best error=0.3604\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 1.9s,\testimator lgbm's best error=0.3604,\tbest estimator lgbm's best error=0.3604\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 1.9s,\testimator lgbm's best error=0.3604,\tbest estimator lgbm's best error=0.3604\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 2.1s,\testimator lgbm's best error=0.3544,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 2.1s,\testimator xgboost's best error=0.3818,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 2.2s,\testimator xgboost's best error=0.3818,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:27:15] {2541} INFO -  at 2.5s,\testimator extra_tree's best error=0.4160,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:15] {2347} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 12-26 13:27:16] {2541} INFO -  at 2.9s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:16] {2347} INFO - iteration 14, current learner rf\n",
            "[flaml.automl: 12-26 13:27:16] {2541} INFO -  at 3.2s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:16] {2347} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:16] {2541} INFO -  at 3.3s,\testimator xgboost's best error=0.3774,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:16] {2347} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:16] {2541} INFO -  at 3.4s,\testimator lgbm's best error=0.3544,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:16] {2347} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:27:17] {2541} INFO -  at 3.7s,\testimator extra_tree's best error=0.3880,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:17] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:17] {2541} INFO -  at 4.1s,\testimator lgbm's best error=0.3544,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:17] {2347} INFO - iteration 19, current learner rf\n",
            "[flaml.automl: 12-26 13:27:17] {2541} INFO -  at 4.5s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3544\n",
            "[flaml.automl: 12-26 13:27:17] {2347} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:18] {2541} INFO -  at 5.4s,\testimator lgbm's best error=0.3480,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:18] {2347} INFO - iteration 21, current learner rf\n",
            "[flaml.automl: 12-26 13:27:19] {2541} INFO -  at 5.8s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:19] {2347} INFO - iteration 22, current learner catboost\n",
            "[flaml.automl: 12-26 13:27:19] {2541} INFO -  at 6.2s,\testimator catboost's best error=0.3624,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:19] {2347} INFO - iteration 23, current learner rf\n",
            "[flaml.automl: 12-26 13:27:19] {2541} INFO -  at 6.5s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:19] {2347} INFO - iteration 24, current learner rf\n",
            "[flaml.automl: 12-26 13:27:20] {2541} INFO -  at 7.0s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:20] {2347} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:20] {2541} INFO -  at 7.1s,\testimator xgboost's best error=0.3726,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:20] {2347} INFO - iteration 26, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:27:20] {2541} INFO -  at 7.4s,\testimator extra_tree's best error=0.3880,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:20] {2347} INFO - iteration 27, current learner catboost\n",
            "[flaml.automl: 12-26 13:27:26] {2541} INFO -  at 12.8s,\testimator catboost's best error=0.3596,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:26] {2347} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:26] {2541} INFO -  at 12.9s,\testimator xgboost's best error=0.3726,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:26] {2347} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:27:26] {2541} INFO -  at 13.3s,\testimator extra_tree's best error=0.3845,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:26] {2347} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:26] {2541} INFO -  at 13.4s,\testimator xgboost's best error=0.3654,\tbest estimator lgbm's best error=0.3480\n",
            "[flaml.automl: 12-26 13:27:26] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:27] {2541} INFO -  at 14.6s,\testimator lgbm's best error=0.3478,\tbest estimator lgbm's best error=0.3478\n",
            "[flaml.automl: 12-26 13:27:27] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:28] {2541} INFO -  at 15.5s,\testimator lgbm's best error=0.3478,\tbest estimator lgbm's best error=0.3478\n",
            "[flaml.automl: 12-26 13:27:28] {2347} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:30] {2541} INFO -  at 17.0s,\testimator lgbm's best error=0.3478,\tbest estimator lgbm's best error=0.3478\n",
            "[flaml.automl: 12-26 13:27:30] {2347} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:30] {2541} INFO -  at 17.2s,\testimator xgboost's best error=0.3607,\tbest estimator lgbm's best error=0.3478\n",
            "[flaml.automl: 12-26 13:27:30] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:31] {2541} INFO -  at 18.3s,\testimator lgbm's best error=0.3467,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:31] {2347} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:31] {2541} INFO -  at 18.5s,\testimator xgboost's best error=0.3607,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:31] {2347} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:31] {2541} INFO -  at 18.6s,\testimator xgboost's best error=0.3607,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:31] {2347} INFO - iteration 38, current learner rf\n",
            "[flaml.automl: 12-26 13:27:32] {2541} INFO -  at 19.4s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:32] {2347} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:32] {2541} INFO -  at 19.6s,\testimator xgboost's best error=0.3607,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:32] {2347} INFO - iteration 40, current learner rf\n",
            "[flaml.automl: 12-26 13:27:33] {2541} INFO -  at 20.0s,\testimator rf's best error=0.3789,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:33] {2347} INFO - iteration 41, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:33] {2541} INFO -  at 20.3s,\testimator xgb_limitdepth's best error=0.3658,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:33] {2347} INFO - iteration 42, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:33] {2541} INFO -  at 20.6s,\testimator xgb_limitdepth's best error=0.3644,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:33] {2347} INFO - iteration 43, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:27:34] {2541} INFO -  at 20.9s,\testimator extra_tree's best error=0.3845,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:34] {2347} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:35] {2541} INFO -  at 22.0s,\testimator lgbm's best error=0.3467,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:35] {2347} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:35] {2541} INFO -  at 22.1s,\testimator xgboost's best error=0.3607,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:35] {2347} INFO - iteration 46, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:35] {2541} INFO -  at 22.4s,\testimator xgb_limitdepth's best error=0.3644,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:35] {2347} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:37] {2541} INFO -  at 23.9s,\testimator xgboost's best error=0.3498,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:37] {2347} INFO - iteration 48, current learner rf\n",
            "[flaml.automl: 12-26 13:27:38] {2541} INFO -  at 24.9s,\testimator rf's best error=0.3746,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:38] {2347} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:39] {2541} INFO -  at 26.3s,\testimator xgboost's best error=0.3498,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:39] {2347} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:41] {2541} INFO -  at 27.7s,\testimator lgbm's best error=0.3467,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:41] {2347} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-26 13:27:43] {2541} INFO -  at 30.2s,\testimator xgboost's best error=0.3495,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:43] {2347} INFO - iteration 52, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:43] {2541} INFO -  at 30.4s,\testimator xgb_limitdepth's best error=0.3581,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:43] {2347} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:44] {2541} INFO -  at 31.3s,\testimator lgbm's best error=0.3467,\tbest estimator lgbm's best error=0.3467\n",
            "[flaml.automl: 12-26 13:27:44] {2347} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:46] {2541} INFO -  at 33.0s,\testimator lgbm's best error=0.3454,\tbest estimator lgbm's best error=0.3454\n",
            "[flaml.automl: 12-26 13:27:46] {2347} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:47] {2541} INFO -  at 33.8s,\testimator lgbm's best error=0.3454,\tbest estimator lgbm's best error=0.3454\n",
            "[flaml.automl: 12-26 13:27:47] {2347} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:50] {2541} INFO -  at 37.3s,\testimator lgbm's best error=0.3454,\tbest estimator lgbm's best error=0.3454\n",
            "[flaml.automl: 12-26 13:27:50] {2347} INFO - iteration 57, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:50] {2541} INFO -  at 37.6s,\testimator xgb_limitdepth's best error=0.3581,\tbest estimator lgbm's best error=0.3454\n",
            "[flaml.automl: 12-26 13:27:50] {2347} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:53] {2541} INFO -  at 40.0s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:27:53] {2347} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:55] {2541} INFO -  at 41.7s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:27:55] {2347} INFO - iteration 60, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:55] {2541} INFO -  at 41.8s,\testimator xgb_limitdepth's best error=0.3581,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:27:55] {2347} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl: 12-26 13:27:57] {2541} INFO -  at 44.3s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:27:57] {2347} INFO - iteration 62, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:27:57] {2541} INFO -  at 44.7s,\testimator xgb_limitdepth's best error=0.3581,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:27:57] {2347} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl: 12-26 13:28:00] {2541} INFO -  at 47.1s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:00] {2347} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:00] {2541} INFO -  at 47.4s,\testimator xgb_limitdepth's best error=0.3581,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:00] {2347} INFO - iteration 65, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:03] {2541} INFO -  at 50.2s,\testimator xgb_limitdepth's best error=0.3514,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:03] {2347} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl: 12-26 13:28:05] {2541} INFO -  at 52.6s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:05] {2347} INFO - iteration 67, current learner lrl1\n",
            "[flaml.automl: 12-26 13:28:06] {2541} INFO -  at 53.0s,\testimator lrl1's best error=0.3736,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:06] {2347} INFO - iteration 68, current learner lrl1\n",
            "[flaml.automl: 12-26 13:28:06] {2541} INFO -  at 53.4s,\testimator lrl1's best error=0.3736,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:06] {2347} INFO - iteration 69, current learner lrl1\n",
            "[flaml.automl: 12-26 13:28:07] {2541} INFO -  at 53.8s,\testimator lrl1's best error=0.3736,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:07] {2347} INFO - iteration 70, current learner lrl1\n",
            "[flaml.automl: 12-26 13:28:08] {2541} INFO -  at 55.6s,\testimator lrl1's best error=0.3703,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:08] {2347} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl: 12-26 13:28:12] {2541} INFO -  at 58.8s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:12] {2347} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:16] {2541} INFO -  at 62.7s,\testimator xgb_limitdepth's best error=0.3488,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:16] {2347} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:18] {2541} INFO -  at 65.6s,\testimator xgb_limitdepth's best error=0.3488,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:18] {2347} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 12-26 13:28:21] {2541} INFO -  at 68.2s,\testimator xgboost's best error=0.3495,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:21] {2347} INFO - iteration 75, current learner lrl1\n",
            "[flaml.automl: 12-26 13:28:23] {2541} INFO -  at 69.8s,\testimator lrl1's best error=0.3703,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:23] {2347} INFO - iteration 76, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:28:23] {2541} INFO -  at 70.3s,\testimator extra_tree's best error=0.3835,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:23] {2347} INFO - iteration 77, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:26] {2541} INFO -  at 73.0s,\testimator xgb_limitdepth's best error=0.3488,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:26] {2347} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 12-26 13:28:33] {2541} INFO -  at 79.7s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:33] {2347} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl: 12-26 13:28:34] {2541} INFO -  at 80.8s,\testimator lgbm's best error=0.3441,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:34] {2347} INFO - iteration 80, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:40] {2541} INFO -  at 86.9s,\testimator xgb_limitdepth's best error=0.3445,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:40] {2347} INFO - iteration 81, current learner catboost\n",
            "[flaml.automl: 12-26 13:28:40] {2541} INFO -  at 87.1s,\testimator catboost's best error=0.3587,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:40] {2347} INFO - iteration 82, current learner rf\n",
            "[flaml.automl: 12-26 13:28:40] {2541} INFO -  at 87.6s,\testimator rf's best error=0.3746,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:40] {2347} INFO - iteration 83, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:28:44] {2541} INFO -  at 91.4s,\testimator xgb_limitdepth's best error=0.3445,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:44] {2347} INFO - iteration 84, current learner catboost\n",
            "[flaml.automl: 12-26 13:28:49] {2541} INFO -  at 96.6s,\testimator catboost's best error=0.3587,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:28:49] {2347} INFO - iteration 85, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:29:01] {2541} INFO -  at 107.8s,\testimator xgb_limitdepth's best error=0.3442,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:29:01] {2347} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:29:08] {2541} INFO -  at 115.0s,\testimator xgb_limitdepth's best error=0.3442,\tbest estimator lgbm's best error=0.3441\n",
            "[flaml.automl: 12-26 13:29:08] {2347} INFO - iteration 87, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:29:26] {2541} INFO -  at 132.8s,\testimator xgb_limitdepth's best error=0.3439,\tbest estimator xgb_limitdepth's best error=0.3439\n",
            "[flaml.automl: 12-26 13:29:26] {2347} INFO - iteration 88, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:29:35] {2541} INFO -  at 142.1s,\testimator xgb_limitdepth's best error=0.3437,\tbest estimator xgb_limitdepth's best error=0.3437\n",
            "[flaml.automl: 12-26 13:29:35] {2347} INFO - iteration 89, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:29:54] {2541} INFO -  at 161.3s,\testimator xgb_limitdepth's best error=0.3423,\tbest estimator xgb_limitdepth's best error=0.3423\n",
            "[flaml.automl: 12-26 13:29:54] {2347} INFO - iteration 90, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:29:54] {2541} INFO -  at 161.7s,\testimator extra_tree's best error=0.3834,\tbest estimator xgb_limitdepth's best error=0.3423\n",
            "[flaml.automl: 12-26 13:29:54] {2347} INFO - iteration 91, current learner rf\n",
            "[flaml.automl: 12-26 13:29:55] {2541} INFO -  at 162.7s,\testimator rf's best error=0.3746,\tbest estimator xgb_limitdepth's best error=0.3423\n",
            "[flaml.automl: 12-26 13:29:55] {2347} INFO - iteration 92, current learner lrl1\n",
            "[flaml.automl: 12-26 13:29:57] {2541} INFO -  at 164.5s,\testimator lrl1's best error=0.3701,\tbest estimator xgb_limitdepth's best error=0.3423\n",
            "[flaml.automl: 12-26 13:29:57] {2347} INFO - iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:30:04] {2541} INFO -  at 171.3s,\testimator xgb_limitdepth's best error=0.3423,\tbest estimator xgb_limitdepth's best error=0.3423\n",
            "[flaml.automl: 12-26 13:30:04] {2347} INFO - iteration 94, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:30:55] {2541} INFO -  at 222.5s,\testimator xgb_limitdepth's best error=0.3421,\tbest estimator xgb_limitdepth's best error=0.3421\n",
            "[flaml.automl: 12-26 13:30:55] {2347} INFO - iteration 95, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:31:38] {2541} INFO -  at 265.0s,\testimator xgb_limitdepth's best error=0.3421,\tbest estimator xgb_limitdepth's best error=0.3421\n",
            "[flaml.automl: 12-26 13:31:38] {2347} INFO - iteration 96, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:31:38] {2541} INFO -  at 265.4s,\testimator extra_tree's best error=0.3791,\tbest estimator xgb_limitdepth's best error=0.3421\n",
            "[flaml.automl: 12-26 13:31:38] {2347} INFO - iteration 97, current learner rf\n",
            "[flaml.automl: 12-26 13:31:39] {2541} INFO -  at 266.5s,\testimator rf's best error=0.3717,\tbest estimator xgb_limitdepth's best error=0.3421\n",
            "[flaml.automl: 12-26 13:31:39] {2347} INFO - iteration 98, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:32:38] {2541} INFO -  at 325.1s,\testimator xgb_limitdepth's best error=0.3402,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:38] {2347} INFO - iteration 99, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:32:38] {2541} INFO -  at 325.6s,\testimator extra_tree's best error=0.3791,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:38] {2347} INFO - iteration 100, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:32:39] {2541} INFO -  at 326.0s,\testimator extra_tree's best error=0.3791,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:39] {2347} INFO - iteration 101, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:32:39] {2541} INFO -  at 326.5s,\testimator extra_tree's best error=0.3712,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:39] {2347} INFO - iteration 102, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:32:40] {2541} INFO -  at 326.9s,\testimator extra_tree's best error=0.3712,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:40] {2347} INFO - iteration 103, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:32:40] {2541} INFO -  at 327.4s,\testimator extra_tree's best error=0.3711,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:40] {2347} INFO - iteration 104, current learner rf\n",
            "[flaml.automl: 12-26 13:32:41] {2541} INFO -  at 328.2s,\testimator rf's best error=0.3686,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:41] {2347} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl: 12-26 13:32:43] {2541} INFO -  at 330.2s,\testimator lgbm's best error=0.3441,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:43] {2347} INFO - iteration 106, current learner rf\n",
            "[flaml.automl: 12-26 13:32:44] {2541} INFO -  at 331.2s,\testimator rf's best error=0.3676,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:44] {2347} INFO - iteration 107, current learner rf\n",
            "[flaml.automl: 12-26 13:32:45] {2541} INFO -  at 331.8s,\testimator rf's best error=0.3629,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:45] {2347} INFO - iteration 108, current learner rf\n",
            "[flaml.automl: 12-26 13:32:46] {2541} INFO -  at 332.9s,\testimator rf's best error=0.3629,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:32:46] {2347} INFO - iteration 109, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:33:11] {2541} INFO -  at 358.7s,\testimator xgb_limitdepth's best error=0.3402,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:33:11] {2347} INFO - iteration 110, current learner rf\n",
            "[flaml.automl: 12-26 13:33:12] {2541} INFO -  at 359.5s,\testimator rf's best error=0.3586,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:33:12] {2347} INFO - iteration 111, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:35:07] {2541} INFO -  at 474.4s,\testimator xgb_limitdepth's best error=0.3402,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:07] {2347} INFO - iteration 112, current learner rf\n",
            "[flaml.automl: 12-26 13:35:08] {2541} INFO -  at 475.4s,\testimator rf's best error=0.3586,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:08] {2347} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl: 12-26 13:35:12] {2541} INFO -  at 478.8s,\testimator lgbm's best error=0.3441,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:12] {2347} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:35:23] {2541} INFO -  at 490.3s,\testimator xgb_limitdepth's best error=0.3402,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:23] {2347} INFO - iteration 115, current learner rf\n",
            "[flaml.automl: 12-26 13:35:24] {2541} INFO -  at 490.8s,\testimator rf's best error=0.3586,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:24] {2347} INFO - iteration 116, current learner lrl1\n",
            "[flaml.automl: 12-26 13:35:25] {2541} INFO -  at 492.5s,\testimator lrl1's best error=0.3701,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:25] {2347} INFO - iteration 117, current learner rf\n",
            "[flaml.automl: 12-26 13:35:27] {2541} INFO -  at 494.3s,\testimator rf's best error=0.3556,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:27] {2347} INFO - iteration 118, current learner rf\n",
            "[flaml.automl: 12-26 13:35:30] {2541} INFO -  at 496.8s,\testimator rf's best error=0.3545,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:35:30] {2347} INFO - iteration 119, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:38:01] {2541} INFO -  at 648.4s,\testimator xgb_limitdepth's best error=0.3402,\tbest estimator xgb_limitdepth's best error=0.3402\n",
            "[flaml.automl: 12-26 13:39:06] {2753} INFO - retrain xgb_limitdepth for 65.1s\n",
            "[flaml.automl: 12-26 13:39:06] {2758} INFO - retrained model: XGBClassifier(colsample_bylevel=0.4530063520214701,\n",
            "              colsample_bytree=0.6359444321807614,\n",
            "              learning_rate=0.04704558926576879, max_depth=12,\n",
            "              min_child_weight=17.317952259324176, n_estimators=289, n_jobs=-1,\n",
            "              reg_alpha=0.0009765625, reg_lambda=324.4066831726308,\n",
            "              subsample=0.827351358517848, use_label_encoder=False,\n",
            "              verbosity=0)\n",
            "[flaml.automl: 12-26 13:39:06] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 13:39:06] {2138} INFO - Time taken to find the best model: 325.1342830657959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHkeDykO4L1w"
      },
      "source": [
        "def create_auc_roc(y1_test_np, automl, x_test):\n",
        "  from sklearn.metrics import roc_curve, roc_auc_score\n",
        "  from matplotlib import pyplot as plt\n",
        "  preds = automl.predict(x_test).reshape(-1, 1)\n",
        "  ns_probs = np.array([0 for _ in range(len(y1_test_np))]).reshape(-1, 1)\n",
        "  print(ns_probs.shape)\n",
        "  ns_auc = roc_auc_score(y1_test_np, ns_probs)\n",
        "  lr_auc = roc_auc_score(y1_test_np, preds)\n",
        "\n",
        "  print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "  print('Trained: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "  ns_fpr, ns_tpr, _ = roc_curve(y1_test_np, ns_probs)\n",
        "  lr_fpr, lr_tpr, _ = roc_curve(y1_test_np, preds)\n",
        "  # plot the roc curve for the model\n",
        "  plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "  plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "  # axis labels\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  # show the legend\n",
        "  plt.legend()\n",
        "  # show the plot\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "2eca7ff7-aaea-4537-844f-3e920eb80aef",
        "id": "EHMc4icq4L1x"
      },
      "source": [
        "create_auc_roc(y1_test_np, automl, x1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67895, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.660\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gU5fbA8e9JKIEQAknoIYTeQzF0KdIERFAsFEVAr3hV1CsWsGG9itfefioKFxtFadIErkpTQIogHaQTOgFCQggk2ff3x2wwQkg2sLuT3T2f58nD7uzszpkAc3bmPXNeMcaglFIqcAXZHYBSSil7aSJQSqkAp4lAKaUCnCYCpZQKcJoIlFIqwBWyO4D8ioqKMrGxsXaHoZRSPmXNmjXHjTFlcnrN5xJBbGwsq1evtjsMpZTyKSKy93Kv6aUhpZQKcJoIlFIqwGkiUEqpAOdzYwQ5SU9PJyEhgbS0NLtDKbBCQkKIjo6mcOHCdoeilCpg/CIRJCQkEBYWRmxsLCJidzgFjjGGxMREEhISqFq1qt3hKKUKGI9dGhKRcSJyVEQ2XuZ1EZH3RWSHiKwXkaZXuq20tDQiIyM1CVyGiBAZGalnTEqpHHlyjGA80C2X17sDNZ0/Q4GPr2ZjmgRyp78fpXzc/pWw9C3rTzfz2KUhY8wSEYnNZZXewJfG6oO9QkRKiUgFY8whT8WklFI+xxjOrfmGInMfQYwDgovCoJlQubnbNmFn1VAlYH+25wnOZZcQkaEislpEVh87dswrweWXiPDYY49deP7mm2/ywgsvuPz+I0eO0LNnTxo1akS9evXo0aMHAIsWLaJnz56XrD9z5kxGjx4NwAsvvMCbb74JwODBg5kyZcpV7IlSynaOTNi7DOY9TdpbDSk6+0FwZIBxQOZ52LPUrZvzicFiY8wYYAxAfHx8gZxJp2jRokybNo2nnnqKqKiofL9/1KhRdOnShUceeQSA9evX57p+r1696NWr1xXFqpQqgDLOwa7FsHUWbPsBzhwjQwqzPKMeB4s2o7+ZgzgyILgIxLZ166btPCM4AFTO9jzaucwnFSpUiKFDh/LOO+9c8tqePXvo2LEjcXFxdOrUiX379l2yzqFDh4iOjr7wPC4u7pJ1Vq1aRZMmTdi5cyfjx49n2LBh7t0JpZR3pZ2GDVPgu8Hwn2ow4TbYOB1HbFteKfY4TdM+ZkXrT7llxOcEDZ4NHZ9x+2UhsPeMYCYwTEQmAS2AJHeND/T9dPkly3rGVWBgq1jOns9k8H8vHWy59ZpobouvzIkz57n/6zV/e23yfa1c2u6DDz5IXFwcTz755N+WP/TQQwwaNIhBgwYxbtw4Hn74YWbMmHHJe/v27cuHH35I586dGTJkCBUrVrzw+rJly3jooYf4/vvviYmJYelS954aKqW8JOUobJ0DW2dbZwCOdCgeBQ36kFy1GyXqdCKocAjxGw/Tq1QIcdGlrPdVbu72BJDFY4lARCYCHYAoEUkAngcKAxhjPgHmAj2AHUAqMMRTsXhLyZIlueuuu3j//fcpVqzYheXLly9n2rRpAAwcOPCSRAFw/fXXs2vXLubNm8cPP/xAkyZN2LjRqrzdsmULQ4cOZcGCBX9LDkopH3Fil3Xw3zIb9v8GGChVBVrcB3V6YqKbMWP9YV6cvpkR3Y7Sv3kM3RqU91p4nqwa6p/H6wZ40BPbzu0bfLEiwbm+HhFaxOUzgJz861//omnTpgwZkv+8FhERwYABAxgwYAA9e/ZkyZIlREZGUqFCBdLS0li7dq0mAqV8gTFweIP1rX/LbDi6yVperiF0GAl1boByDUCEg6fO8syXv7Nw2zGaxJQivkppr4frE4PFviQiIoLbb7+dsWPHcvfddwPQunVrJk2axMCBA/nmm29o2/bSgZ6ff/6Zli1bUrx4cZKTk9m5cycxMTGcOXOGUqVKMXbsWLp06UJoaCgdOnTw8l4ppfLkyIR9K6yD/9bZcGofIBDTCrr+2zr4R/z9zv7v1x3gmekbyXQYRvWsx6DWsQQHef+eH00EHvDYY4/x4YcfXnj+wQcfMGTIEN544w3KlCnDf//730ves2bNGoYNG0ahQoVwOBz84x//oFmzZixatAiAcuXKMXv2bLp37864ceO8tStKqdykp8GuRX9V+qQmWlU91TpA28ehdg8okeNcMACEFytM48qleK1PQypHFPdW1JcQ6wqN74iPjzcXT0yzZcsW6tata1NEvkN/T0q5QVoS/Pk/2DILdvwI51OgSBjU6gp1ekKNzhBSMse3ZmQ6GPvLbtIzHQzrWBOweoF5485/EVljjInP6TU9I1BKqbwkH4FtzsHe3UusSp/QstDwVuvgX7UdFCqa60dsPniaEVPXs+FAEjfEVbiQAApC+xdNBEoplZPEnc7r/XOc/X0MlI61Kn3q3gjRzSAoOM+POZeRyYc/7+DjRTspVbww/3dHU7o3KF8gEkAWTQRKKQVWpc+hP/6q8T+62VpeviF0eArq9oSy9SCfB/A9x1P5ZPFOejWuyHM31KN0aBEPBH91NBEopQKXIxP2Lbcu+WydA0n7QIKsSp/rX7MqfUpXyffHnjmXwf82H+GmJpWoXT6Mn4Z3ICbSvsHgvGgiUEoFlvQ02LXQ+tZ/odKnqFXp0/4Jq9InNP/9wrIs/fMYT03bwIFTZ2lQqSQ1yoYV6CQAmgiUUoHg7Cmr0mfrLPjzR0g/A0VLQs2u1iWfGp2haNhVbSIpNZ1/z93Mt6sTqBYVyuShrahR9uo+01s0EbhJiRIlSElJuarPWL16NV9++SXvv/9+jq/v2bOHZcuWMWDAAJfWVyqgJR/+63r/7qVWpU+JchB3u3Xwj20HhdxzvT7TYbjlk2XsPn6GBzpU5+FONQkpnPdAckGhiaAAiY+PJz4+xzJfwEoEEyZMuJAI8lpfqYCTuNOq7986GxJWWcsiqkHL+60yz+hmEOS+pssnzpynVLHCBAcJT1xfm0qlitGgUrjbPt9b7GxDbS8PTvuWZd26dbRs2ZK4uDhuvvlmTp48CVjtpOPi4mjcuDFPPPEEDRo0AP4+Cc3ixYtp3LgxjRs3pkmTJiQnJzNy5EiWLl1K48aNeeedd/62fkpKCkOGDKFhw4bExcUxdepUj+2XUgWGMXBwLfz8CnzUEj5oCj8+b03ect0zcP9yeOh36PoyxLRwWxIwxjB1TQLXvbmISaus+bWur1/eJ5MA+OMZwQ8jrWZPuTl3Go5stGb7kSCr+VPRnO8EBKzyse6j8x3KXXfdxQcffED79u0ZNWoUL774Iu+++y5Dhgzhs88+o1WrVowcOTLH97755pt89NFHtGnThpSUFEJCQhg9ejRvvvkms2fPBrjQfgLg5ZdfJjw8nA0brH3PSjpK+Z3MDKvSJ6vGP2m/s9KnNXQbbVX6lIrx2OYTTqby9PSNLNl+jGuqlKZ51QiPbctb/C8RuCItyUoCYP2ZlpR7IrgCSUlJnDp1ivbt2wMwaNAgbrvtNk6dOkVycjKtWlkdTgcMGHDhwJ5dmzZtGD58OHfccQd9+vT526Q1Ofnxxx+ZNGnSheelS3u/g6FSHpN+FnZmq/Q5e8Kq9Kne0ermWavbVVX6uGr62gSenb4RA7zYqz4DW1YhyIYmce7mf4nAlW/u+1fCF72s08fgInDL5x6b8OFKjRw5khtuuIG5c+fSpk0b5s+fb3dISnnX2VPw5wJnT5+fnJU+4VDreutbf43OULSEV0OKCC3KNbERvHpzA6JLF+yS0Pzwv0TgisrNrene9iy15v70QBIIDw+ndOnSLF26lLZt2/LVV1/Rvn17SpUqRVhYGL/99hstWrT427f47Hbu3EnDhg1p2LAhq1atYuvWrVSuXJnk5OQc1+/SpQsfffQR7777LmBdGtKzAuVzTh/6q6fPnqXWhO0lykOjvtZgb2xbt1X6uCI908FnS3eRkWl4uFNN2tcqQ7uaUQWqPYQ7BGYiALdP+5aamvq3yzfDhw/niy++4J///CepqalUq1btQvvpsWPHcu+99xIUFET79u0JD790gOndd99l4cKFBAUFUb9+fbp3705QUBDBwcE0atSIwYMH06RJkwvrP/vsszz44IM0aNCA4OBgnn/+efr06eO2/VPKY47vsOr7t8yGA87OwhHVodWDUOdGqHSNWyt9XLXxQBIjpq5n08HT3NioYoFqEudu2obaBikpKZQoYZ3Sjh49mkOHDvHee+95fLu+9ntSfiqr0idrsPfYVmt5hcZWfX+dnlCmTr57+rhLWnom7//0J58u2UXp4kV45ab6dGtQwZZY3EnbUBcwc+bM4bXXXiMjI4MqVaowfvx4u0NSyrMyM2Dfsr96+pxOsCp9qrSBa4Y4K30q2x0lAHsTU/ls6S76NKnEszfUI7x4YbtD8jhNBDbo27cvffv2tTsMpTwr/Szs/Nk6+G//Ac6ehEIhVqXPdU87K30i7Y4SsJrEzd90mD5No6ldPoyfH+tg64xh3uY3icBbs/z4Kl+7BKh81NmTsH2+Vemz82dIT4WQcOugX6cn1OgERULtjvJvFm8/xtPTNnAw6Sxx0eHUKBsWUEkA/CQRhISEkJiYSGRkpCaDHBhjSExMJCQkxO5QlD86ffCvnj57fslW6dPf2dOnLQQXvMsrJ8+c5+U5m5n2+wGqlwnlu/t8p0mcu/lFIoiOjiYhIYFjx47ZHUqBFRISkudNaUq57Piff/X0ObDGWhZZA1oNs2bvqtjUlkofV2U1idubmMqw62owrGMNn2oS525+kQgKFy5M1apV7Q5DKf9lDBz83TnYOxuOb7eWV2wCHZ+zDv5RtWyr9HFVYso5ShcvQnCQMLJbHSqVLkb9ir7ZH8id/CIRKKU8IDMd9v7qvOwzB04fAAmG2DbQ7F6o0wPCfeMs0xjDd2sSeGX2ZkZ0r8MdLarQtX55u8MqMDQRKKX+cj7VGuTN6umTdspZ6dMJOj5rDfoW960ma/tPpPL09A0s/fM4zWMjaFWtYFQqFSSaCJQKdKknrEqfrbOtnj4ZZ52VPt2twd7qHQtcpY+rpv2ewLMzNiLAyzc14I7mMX7RJM7dNBEoFYiSDvy90sdkQlhFaHKndfCv0qZAVvrkV1SJojSvGsG/b25IpVLF7A6nwNJEoFSgOLb9r54+B3+3lkXWhDYPWz19KjYp0JU+rkjPdPDp4p1kOuCRzjVpV6sM7WqVsTusAk8TgVL+yuFw9vRxHvwT/7SWV2wKnUZZB/8yteyN0Y02HkjiiSnr2XLoNL0bV9SbTPNBE4FS/iQz3brUk1Xpk3zQWelzLbS4D2r3gPBKdkfpVmnpmbz74598tnQXEaFF+HTgNVyvFUH54tFEICLdgPeAYOBzY8zoi16PAb4ASjnXGWmMmevJmJTyO+fPZOvpM89Z6VPMaudQZ5Q1kYuPVfrkx74TqYz9ZRe3No3m6R51A6JJnLt5LBGISDDwEdAFSABWichMY8zmbKs9C3xrjPlYROoBc4FYT8WklN9IPWEd9LfMtpJAxlkIKQW1u1s9fap3hCL+2y8nOS2deRsPc1t8ZWqVC2Ph4x38asYwb/PkGUFzYIcxZheAiEwCegPZE4EBsiYLDgcOejAepXxbUkK2Sp9frUqfkpWg6UDr4F+ltV9U+uRl4dajPDN9A4dPp9EkphQ1yoZpErhKnkwElYD92Z4nAC0uWucFYIGIPASEAp1z+iARGQoMBYiJiXF7oEoVSMbAsW3OCVxmWwO/AFG14dp/WT38KzYt8G0d3OXEmfO8PHsz09ceoGbZEky5v3XANolzN7sHi/sD440xb4lIK+ArEWlgjHFkX8kYMwYYA9YMZTbEqZR3OBzOnj7Ohm6JO6zlleKh0/POnj417Y3RBpkOw60fL2PfiVQe7lSTB6+rTtFCgdskzt08mQgOANmnHIp2LsvuHqAbgDFmuYiEAFHAUQ/GpVTBkpluTdS+ZTZsmwvJhyCokLPS55/WN/+SFe2O0hbHks8RGWo1iXu6R10qlS5G3Qol836jyhdPJoJVQE0RqYqVAPoBAy5aZx/QCRgvInWBEEB7SSv/d/4M7PjRuua/fR6kJUHh4s5KnxuhVlcoVtruKG1jjOHb1ft5Zc4WRnSrw50tq9C5Xjm7w/JbHksExpgMERkGzMcqDR1njNkkIi8Bq40xM4HHgM9E5FGsgePBRqfSUv4q9YTVyG1rVqVPmnWwr9PT+tZf7Tq/rvRx1b7EVEZOW8+ynYm0qBrBtTWi7A7J74mvHXfj4+PN6tWr7Q5DKdec2v9Xpc/eZc5Kn2jrwF+3J8S0hmC7h+oKjilrEnhuxkaCg4SnetShfzNtEucuIrLGGBOf02v6L1ApdzIGjm21DvxbZsOhddbyMnXg2ketg3+FxgFT6ZNf5UoWpXX1SF65uQEVwrVJnLdoIlDqajkc1nSNWT19Tuy0lkc3g84vWpd+omrYG2MBdT7DwceLduIwhke71KJtzTK0ralN4rxNE4FSVyLjvFXps3U2bJ0LKYedlT5todUDUPsGKFnB7igLtD/2n+LJKevZdiSZPk0qaZM4G2kiUMpV51KyVfrMh3NZlT6drfr+ml2hWCm7oyzwzp7P5O3/bWPsL7spGxbC53fFa0WQzTQRKJWbM4mw/Qfrks+uhc5KnwjrwF+3J1TrAIX1WnZ+7D+ZyhfL9tKveQwju9ehZIj/t8Uo6DQRKHWxU/usb/1bZsO+ZWAcEF4ZrhliVfvEtNJKn3w67WwSd7uzSdyiJzpQUWcMKzD0X7NSxsDRLX/19Dn0h7W8TF1o+5g12FuhkVb6XKGftx7h6WkbOZqcRtOY0tQoW0KTQAGjiUAFJocDDqz+q6fPiV3W8ujm0OUl6+AfWd3eGH1cYso5Xpq9me/XHaR2uTA+GXgNNcqWsDsslQNNBCpwZJyHPUv+6umTcgSCCkPVdtD6IWv2rjCd2codMh2G2z5Zzv6TqTzauRb3d6hOkUK+PR+yP9NEoPzbuRTY8T9npc8CZ6VPKNTsbPX0qdlFK33c6GhyGlGhRQkOEp65oS7RpYtTu7y2ii7oXE4EIlLcGJPqyWCUcoszx7P19FkImeegeCTUu9E6+FfrAIVD7I7Srzgchomr9vHa3K2M6F6HgS2r0KmuloT6ijwTgYi0Bj4HSgAxItIIuM8Y84Cng1PKZSf3/tXTZ99yZ6VPDDS7x7reX7mFVvp4yJ7jZxg5bT0rdp2gdfVI2uudwT7Hlf8Z7wDXAzMBjDF/iEg7j0alVF72/QabpsH5VKufz+H11vKy9aHt41aNf/k4rfTxsG9X7+e5GRspEhzE6D4N6dusst4d7INc+opkjNl/0V9upmfCUcoFG76DqfdidS4HytaDLi9bNf5a6eNVlUoVo12tMrzcuwHlw/Vym69yJRHsd14eMiJSGHgE2OLZsJS6jNQTMOdxLiQBCYaGt0Kbh20NK1Ccy8jk/xbuxBjD8K61aVMjijY6X4DPc6We65/Ag1iT0R8AGgM6PqC8L+M8TB5oze4VXNRKAsFFrEZvyuPW7jvJjR/8wns//cmBU2n42lwm6vJcOSOobYy5I/sCEWkD/OqZkJTKgTEw93HY+wv0+RxKV7G6f8a2hcrN7Y7Or6Wez+CtBdsZ9+tuypcMYdzgeDrW0Yogf+JKIvgAaOrCMqU8Z8XH8PsX0O4JiLvNWqYJwCsOnDzLVyv2ckeLGEZ0q0OYNonzO5dNBCLSCmgNlBGR4dleKok1B7FS3rF9ASx4Bur2gg5P2x1NQEg6m84PGw7Rr3kMNcuFsfiJDjpjmB/L7YygCNa9A4WA7LcGngZu9WRQSl1wdAtMuRvKNYCbP4EgbVPgaQs2HebZGRtJPHOe+NgIapQtoUnAz102ERhjFgOLRWS8MWavF2NSynImESb0hSLFof8kKBJqd0R+7XjKOV6YuYnZ6w9Rp3wYnw+K1yZxAcKVMYJUEXkDqA9cKBQ2xnT0WFRKZZyHyXdajeEGz4XwSnZH5NcyHYZbP17GwVNpPN61Fve1r07hYD37ChSuJIJvgMlAT6xS0kHAMU8GpQKcMTD7UWtSmFvHQfQ1dkfkt46cTqNMCatJ3PM31ie6dDFqltMmcYHGlZQfaYwZC6QbYxYbY+4G9GxAec7yD2Hd19B+BDS4xe5o/JLDYfhqxV46vbWYb36zrvxeV6esJoEA5coZQbrzz0MicgNwEIjwXEgqoG2bBwueg3o3QfuRdkfjl3YdS2HktA2s3H2Ca2tE0aF2WbtDUjZzJRG8IiLhwGNY9w+UBP7l0ahUYDqyGabeY00LedPHWiHkAZNX7WPU95soWiiI/9wax23XRGuTOJV3IjDGzHY+TAKugwt3FivlPinHYGJfKBoG/SdalULK7aJLF6dDbatJXNmS2iROWXK7oSwYuB2rx9A8Y8xGEekJPA0UA5p4J0Tl9zLOOSuEjsGQuVCyot0R+Y1zGZl88NMOAB6/XpvEqZzldkYwFqgMrATeF5GDQDww0hgzwxvBqQBgDMx6BPavgFv/C5W0c4m7rNl7gienrGfnsTPcHh+NMUYvA6kc5ZYI4oE4Y4xDREKAw0B1Y0yid0JTAeHX9+CPiVbriAZ97I7GL5w5l8Eb87fxxfI9VAwvxhd3N6d9LZ01TF1ebqNx540xDgBjTBqwK79JQES6icg2EdkhIjmWgIjI7SKyWUQ2iciE/Hy+8nFb58KPL1glou2ftDsav3Hw1FkmrNzHXS2rMP/RdpoEVJ5yOyOoIyLO+f8QoLrzuQDGGBOX2wc7xxg+AroACcAqEZlpjNmcbZ2awFNAG2PMSRHROrZAcXgjTP0HVGwCvT/SKSWvUlJqOnM2HGJAC6tJ3NInr6OcDgYrF+WWCOpe5Wc3B3YYY3YBiMgkoDewOds69wIfGWNOAhhjjl7lNpUvSDkKE/tBSLhVIVRYG5pdjXkbD/Pc9xs5ceY8LapFUL1MCU0CKl9yazp3tY3mKgH7sz1PAFpctE4tABH5Fau19QvGmHkXf5CIDAWGAsTExFxlWMpW6Wkw6Q44cxzungdh5e2OyGcdTU7jhZmbmLvhMPUqlOS/g5tRvYw2iVP559Lk9R7efk2gAxANLBGRhsaYU9lXMsaMAcYAxMfH6/x4viqrQihhJdz+JVRsbHdEPivTYbj9k+UcTErjietrM7RdNW0Sp66YJxPBAazy0yzRzmXZJQC/GWPSgd0ish0rMazyYFzKLr+8A+snQcdnoV5vu6PxSYeSzlIuLMRqEterPpVLF9dW0eqqufQVQkSKiUjtfH72KqCmiFQVkSJAP2DmRevMwDobQESisC4V7crndpQv2DILfnoRGt4GbR+3Oxqf43AYxv+6m05vLebrrCZxtctqElBukWciEJEbgXXAPOfzxiJy8QH9EsaYDGAYMB/YAnxrjNkkIi+JSC/navOBRBHZDCwEntD7FPzQoT9g2lCoFA+9PtAKoXzacTSF2z9dzguzNhMfG0HHOlpcp9xLjMn9kruIrMFqO73IGNPEuWyDMaahF+K7RHx8vFm9erUdm1ZXIvkIfHYdIHDvzxBWzu6IfMqklfsYNXMTxQoHM6pnPfo0raR3B6srIiJrjDHxOb3mUhtqY0zSRf/4dMBW5S09DSYNgLMn4e75mgSuQExkcTrXLcuLvRpQJqyo3eEoP+VKItgkIgOAYOcNYA8DyzwblvJ5xsDMYXBgNfT9Birkev+hckpLz+T9n/4E4MludWhdPYrW1bVJnPIsVwaLH8Kar/gcMAGrHbXOR6Byt/RN2PAddBoFdXvaHY1PWL3nBD3eX8r/LdrJiTPnyeuyrVLu4soZQR1jzDPAM54ORvmJzd/Dz69AXF+4drjd0RR4KecyeGPeVr5csZdKpYrx5d3Naaf9gZQXuZII3hKR8sAUYLIxZqOHY1K+7OA6mP5PiG4ON76vFUIuOJx0lkmr9jOoVSxPXF+b0KJ23+epAk2el4aMMddhzUx2DPhURDaIyLMej0z5nuTDMLE/FI+Eft9AYe13czknz5znqxXW/QA1ylpN4l7oVV+TgLKFSzeUGWMOG2PeB/6JdU/BKI9GpXxP+lkrCaQlQf9JUEJr3XNijGHuhkN0eWcxL87cxM5jKQA6baSyVZ5fP0SkLtAXuAVIBCZjTWSvlMUYmPEAHFwL/SZA+QZ2R1QgHT2dxnPfb2T+piM0rBTOl3e30CZxqkBw5Tx0HNbB/3pjzEEPx6N80eL/wKZp0PlFqNPD7mgKpEyH4bZPl3M4KY2nutfhnmurUkibxKkCIs9EYIxp5Y1AlI/aNB0WvQqNBkCbR+yOpsA5eOos5UtaTeJe6t2AyqWLUU3PAlQBc9mvJCLyrfPPDSKyPtvPhmwzl6lAduB3mH4/VG4JN76rFULZZDoM/72oSVz7WmU0CagCKbczgqyvd3o3kLrU6YNW+4jQMtD3ayik7Q+y7DiazJNT1vP7vlN0qF2GTnW1tYYq2HKboeyQ8+EDxpgR2V8TkdeBEZe+SwWE86lWhdC5ZLhnAZTQm5+yTPhtHy/M3ERo0WDe6duImxprkzhV8LkyWtUlh2Xd3R2I8hEOB8y432otfctYKFff7ogKlNio4nStX47/DW/PzU2iNQkon3DZMwIRuR94AKh20ZhAGPCrpwNTBdTi12HzDOj6CtTuZnc0tktLz+SdH7cjCCO7a5M45ZtyGyOYAPwAvAaMzLY82RhzwqNRqYJpwxRYPBoa3wmthtkdje1+25XIyGkb2H38DHe0iMEYo2cAyifllgiMMWaPiDx48QsiEqHJIMAkrIHvH4SY1tDz7YCuEEpOS+f1eVv5esU+YiKKM+EfLWhdQ88ClO/K64ygJ7AGayKa7P/zDVDNg3GpgiTpAEzqDyXKQd+vAr5C6Mjpc0xZk8A/rq3K8K61KF5E+wMp35Zb1VBP559VvReOKnDOn7GSwPlUuOt7CA3Mb74nzpxnzvqDDGwVS42yJVj6ZEedMUz5DVd6DbUB1hljzojInUBT4F1jzD6PR6fs5XBYLaUPb4D+k6FsXbsj8jpjDLPXH+KFmZs4nZZOmxpRVCtTQpOA8iuulI9+DKSKSCOsZnM7ga88GpUqGBa9CltmWhVCtbraHY3XHTmdxr1frhjDcygAABvpSURBVOGhiWupVLoYsx66Vu8MVn7JlYubGcYYIyK9gQ+NMWNF5B5PB6Zstv47WPIGNL0LWj5gdzRel+kw3O5sEvdMj7oMaROrTeKU33IlESSLyFPAQKCtiAQBhT0blrJVwmqrQqjKtdDjrYCqEEo4mUqF8GIEBwkv925ATERxYqNC7Q5LKY9y5StOX6yJ6+82xhwGooE3PBqVsk9SgtU+omRFZ4VQEbsj8opMh+Hzpbvo/PZivnbOHNauVhlNAioguNKG+rCIfAM0E5GewEpjzJeeD0153bkUmNAPMtJg8GwoHmF3RF6x7XAyT05dzx/7T9GpTlm61tcmcSqwuFI1dDvWGcAirHsJPhCRJ4wxUzwcm/ImhwOm3wdHN8GA76BMbbsj8oqvV+zlxVmbCAspzHv9GtOrUUW9O1gFHFfGCJ4BmhljjgKISBngR0ATgT9Z+ApsnQ3dXoeane2OxuOy2kHUKFuCHg0rMKpnPSJLaEmoCkyuJIKgrCTglIiLk94rH/HHZFj6FlwzBFrcZ3c0HnX2fCZv/28bQUHCU93r0rJaJC2rRdodllK2ciURzBOR+cBE5/O+wFzPhaS8av9KmDkMYttCjzf8ukJo+c5ERk5bz97EVAa2rKJN4pRycmWw+AkR6QNc61w0xhgz3bNhKa84tc+aZSw8Gm7/EoL9syr4dFo6r83dysSV+6gSWZwJ97bQVtFKZZPbfAQ1gTeB6sAG4HFjzAFvBaY87FyKVSaacR4GT/brCqGjp88xY+0BhrarxqOda1GsSLDdISlVoOR2rX8cMBu4BasD6Qf5/XAR6SYi20Rkh4iMzGW9W0TEiEh8frehroDDAdPuhaNb4PbxUKaW3RG5XWLKOcb/uhuAGmVL8MuI63i6R11NAkrlILdLQ2HGmM+cj7eJyO/5+WARCQY+wprqMgFYJSIzjTGbL1ovDHgE+C0/n6+uwk8vwra50ONNqN7R7mjcyhjDzD8O8sLMTaScy6BdrTJUK1NCK4KUykVuiSBERJrw1zwExbI/N8bklRiaAzuMMbsARGQS0BvYfNF6LwOvA0/kM3Z1JdZNgF/fhfh7oPm9dkfjVgdPneXZGRv5eetRGlcuxX9ujdMmcUq5ILdEcAh4O9vzw9meGyCvr5KVgP3ZnicALbKvICJNgcrGmDkictlEICJDgaEAMTExeWxWXda+FTDrEajaHrq/bnc0bpWR6aDfmBUcSz7Hcz3rMbh1LMFBWhGklCtym5jmOk9u2Nm87m1gcF7rGmPGAGMA4uPjjSfj8lsn98KkO6BUDNz+hd9UCO0/kUrFUsUoFBzEqzc3JCaiODGRxe0OSymf4skbww4AlbM9j3YuyxIGNAAWicgeoCUwUweMPeBcMkzsB450a4KZYqXtjuiqZWQ6GLNkJ53fXsxXy/cAcG3NKE0CSl0BT062ugqoKSJVsRJAP2BA1ovGmCTgQjG3iCzCKlFd7cGYAo8jE6b+A45tgzunQlQNuyO6alsOnWbE1PWsT0iiS71ydG9Ywe6QlPJpHksExpgMERkGzAeCgXHGmE0i8hKw2hgz01PbVtn8+Dxsnwc3vAXVPXq1zyu+Wr6HF2dtJrxYYT4c0IQbGlbQu4OVukqudB8V4A6gmjHmJRGJAcobY1bm9V5jzFwuakdhjBl1mXU7uBSxct3ar2HZB9B8KDT7h93RXJWsdhC1yoVxY6OKPNezHhGhgTFXglKe5soZwf8BDqwqoZeAZGAq0MyDcamrtXcZzPqXdZ/A9a/ZHc0VSz2fwZvzt1MoWHi6R11aVIukhTaJU8qtXBksbmGMeRBIAzDGnAT0q1hBdmK3VSFUOhZu/S8Ee3IoyHN+3XGc699dwrhfd3M+w4ExWjCmlCe4coRId94lbODCfAQOj0alrlzaaatCyDhgwGQoVsruiPIt6Ww6r87ZwuTV+6kaFcq397WieVX/7YWklN1cSQTvA9OBsiLyb+BW4FmPRqWujCMTpt4DiTtg4HSIrG53RFfkeMo5Zq0/yD/bV+dfnWsSUlj7AynlSa60of5GRNYAnbDaS9xkjNni8chU/v1vFPy5AHq+A1Xb2R1NvhxLPsesPw5y97VVqV6mBL+M6KiDwUp5iStVQzFAKjAr+zJjzD5PBqbyac0XsPxDaHE/xN9tdzQuM8YwY90BXpy1mdRzmVxXpyxVo0I1CSjlRa5cGpqDNT4gQAhQFdgG1PdgXCo/di+FOcOheifo+ord0bjswKmzPDN9A4u2HaNpjNUkrmpUqN1hKRVwXLk01DD7c2ejuAc8FpHKnxO74NuBEFEdbvOdCiGrSdxyElPO88KN9RjYSpvEKWWXfB81jDG/i0iLvNdUHpeWBBP6WY8HTIKQcHvjccG+xFQqlbaaxI3uE0dMRHEqR2h/IKXs5MoYwfBsT4OApsBBj0WkXJOZAd8NgRM74a7vIaKa3RHlKiPTwWdLd/POj9t5qnsdhrSpSpsaOm+wUgWBK2cEYdkeZ2CNGUz1TDjKZQuehZ0/Qa8PIPZau6PJ1aaDSYyYup6NB05zff1y3KBN4pQqUHJNBM4bycKMMY97KR7litXj4LePoeWD0PQuu6PJ1RfL9vDy7M2UKl6Ej+9oqp1ClSqALpsIRKSQs4NoG28GpPKwewnMfQJqdoWuL9sdzWVlNYmrUz6M3o0r8VzPupQqriWhShVEuZ0RrMQaD1gnIjOB74AzWS8aY6Z5ODZ1scSdMHkgRNaAW8ZCUMG74/bMuQzemL+NwsHCMzfU0yZxSvkAV8YIQoBErO6jWfcTGEATgTedPQUT+loH//6TIKSk3RFdYsn2Yzw1bQMHk84yqFXshbMCpVTBllsiKOusGNrIXwkgi7aB9KbMDPhuMJzcA4NmQkRVuyP6m6TUdF6es5kpaxKoVsZqEtcsVpvEKeUrcksEwUAJ/p4Asmgi8Kb5T8GuhdDrQ6jS2u5oLnH8zDl+2HCIBzpU5+FO2iROKV+TWyI4ZIx5yWuRqJyt+hxWjoHWD0HTgXZHc8HR5DRmrjvIP9pWu9AkrrT2B1LKJ+WWCPTirt12LoS5T0KtbtD5RbujAaxqoKm/H+Dl2Zs5m55Jp7rlqBoVqklAKR+WWyLo5LUo1KWO74DvBkGZ2nDL5wWiQmj/iVSenr6BpX8eJ75KaUbfok3ilPIHl00ExpgT3gxEZXP2JEy4HYIKWxVCRcPyfo+HZWQ66P/ZCk6eOc/LvetzR4sqBGmTOKX8gm+0qgwkmenw7SBI2g93zYTSVWwNZ8/xM1SOKE6h4CD+c6vVJC66tDaJU8qfuDJ5vfKmeSNh92K48T2o0sq2MNIzHXy0cAdd31nCl8v3ANC6epQmAaX8kJ4RFCQrP7OqhNr8CxoPsC2MjQeSeHLKejYfOs0NDSvQM66ibbEopTxPE0FBseMn+GEE1O4BnZ63LYz//rqbV+ZsISK0CJ/ceQ3dGpS3LRallHdoIigIjm235hYoWxf6jIEg71+xy2oHUb9iOH2aVOLZG+oRXryw1+NQSnmfJgK7pZ6AiX2hUBHoP9HrFUIp5zL4z7ytFAkO4tme9WheNYLmVbU9hFKBRAeL7ZSZDt/eBUkJ0G8ClIrx6uYXbTvK9e8s4asVezFYZwVKqcCjZwR2MQbmPg57lsLNY6Byc69t+uSZ87w8ZzPTfj9AjbIlmPLP1lxTpbTXtq+UKlg0Edjlt09hzXi4djg06uvVTZ9MPc+CTUd4uGMNHuxYg6KF7L9rWSllH49eGhKRbiKyTUR2iMjIHF4fLiKbRWS9iPwkIvbePeUtf/5odRSt0xM6PueVTR49ncaYJTsxxlCtTAl+HdGR4V1raxJQSnkuETjnO/4I6A7UA/qLSL2LVlsLxBtj4oApwH88FU+BcWwbTBkC5erDzZ96vELIGMO3q/bT6e3FvLVgO3sSUwG0IkgpdYEnLw01B3YYY3YBiMgkoDewOWsFY8zCbOuvAO70YDz2Sz1h9RAqFOLsIVTCo5vbfyKVp6Zt4Jcdx2leNYLRfRpqkzil1CU8mQgqAfuzPU8AWuSy/j3ADzm9ICJDgaEAMTHeraxxm4zz1nzDpw/BkLkQHu3ZzTmbxJ1KTeeVmxowoHmMNolTSuWoQAwWi8idQDzQPqfXjTFjgDEA8fHxvlfjaAzMGQ57f4E+n0N0vMc2tfv4GWKcTeLeuLURVSKLU7FUMY9tTynl+zx5gfoAUDnb82jnsr8Rkc7AM0AvY8w5D8ZjnxX/B2u/gnZPQNxtHtlEeqaDD376k+vfWcIXy/YA0Kp6pCYBpVSePHlGsAqoKSJVsRJAP+BvndREpAnwKdDNGHPUg7HYZ/sCWPAs1O0FHZ72yCbWJ5ziySnr2Xo4mRsbVaRXY20Sp5RynccSgTEmQ0SGAfOBYGCcMWaTiLwErDbGzATeAEoA34kIwD5jTC9PxeR1R7fAlLuhXAO4+ROPVAiN+2U3r8zZTJmwonx2Vzxd6pVz+zaUUv7No2MExpi5wNyLlo3K9rizJ7dvqzPHYUJfKFLcqhAq4t5qnawmcXHR4fRtVpmR3esSXkxLQpVS+VcgBov9TlaFUMoRGDwXwiu57aOT09IZ/cNWihYKZtSN9YiPjSA+VpvEKaWunDadczdjYPajsG8Z3PR/EH2N2z564dajdH1nCRNX7qNQsGiTOKWUW+gZgbst/xDWfQ3tR0KDW9zykSfOnOelWZuYse4gtcqV4P/uaE2TGG0Sp5RyD00E7rRtHix4DurdBO1HuO1jk86m89OWozzSqSYPXleDIoX0RE4p5T6aCNzlyCaYeg9UaAQ3fXzVFUKHk9KYse4A97WrRtWoUH4Z2VEHg5VSHqGJwB1SjsHEftbsYv0nWpVCV8gYw6RV+3l1zhbSHQ661S9PbFSoJgGllMdoIrhaGedg8p1WMhgyF0pe+c1cexPPMHLqBpbvSqRltQhG94kjVpvEKaU8TBPB1TAGZj0C+1fAbeOhUtMr/qiMTAcDPvuNpLPpvHpzQ/o1q6xN4pRSXqGJ4Gr8+h78MdFqHVH/5iv6iJ3HUqjibBL31u1Wk7gK4dofSCnlPVp+cqW2zoUfX7BKRNs/me+3n89w8O6P2+n27hK+XL4XgJbVIjUJKKW8Ts8IrsThjTD1H1CxCfT+CCR/l3DW7T/FiCnr2XYkmd6NK3JTE/fdeayUUvmliSC/Uo5aFUIh4VaFUOH8fYMf+8tu/j1nM2XDQhg7KJ5OdbVJnFLKXpoI8iM9DSbdYTWUu3sehJV3+a1ZTeIaVw6nX/MYRnavQ8kQLQlVStlPE4GrjIFZD0PCSrj9S6jY2KW3nU5L57W5WwkpHMTzN9bnmioRXFNFm8QppQoOHSx21S/vwPrJ0PFZqNfbpbf8uPkIXd5ezORV+yhSKEibxCmlCiQ9I3DFllnw04vQ8DZo+3ieqyemnOPFWZuZ+cdB6pQPY8zAeBpVLuWFQJVSKv80EeTl0B8wbShUiodeH7pUIZSclsHCbUd5tHMt7u9QXZvEKaUKNE0EuUk+AhP7Q7EI6DcBCodcdtWDp84yfe0BHuhQndioUH4d2VEHg5VSPkETweWkp8GkAXD2JNw9H8JyLvN0OAwTVu5j9A9byXQYbmhYgdioUE0CSimfoYkgJ8bAzGFwYDX0/QYqxOW42u7jZxg5dT2/7T5BmxqRvHZzHDGRV955VCml7KCJICdL34QN30GnUVC3Z46rZGQ6uPPz3zidls5/bonjtvhoJJ93GCulVEGgieBim7+Hn1+BuL5w7fBLXt5xNJnYyFAKBQfxTt/GVIksTrmSlx87UEqpgk7LWbI7uA6m3QfRzeHG9/9WIXQuI5O3/7edbu8u5Qtnk7jmVSM0CSilfJ6eEWRJPmxVCIVGQb9v/lYh9Pu+k4yYsp4/j6bQp0kl+miTOKWUH9FEAJB+1koCaUlwzwIoUfbCS58t2cWrP2yhQskQ/jukGdfVLpvLBymllO/RRGAMzHgADq617hUo3wCwykKDgoSmVUpxR4sYRnSrQ5iWhCql/JAmgsX/gU3ToPOLUKcHSWfT+feczRQrHMyLvRtokzillN8L7MHiTdNh0avQaAC0eYT5mw7T5e3FTP39AKFFC2mTOKVUQAjcM4IDv8P0+6FyS45f9zrPT1jLnA2HqFehJOMGN6NBpXC7I1RKKa8IzERw+qDVPiK0DPT9mpS0YJb+eYwnrq/N0HbVKBwc2CdKSqnAEniJ4HwqTOyPI+00k+PG0i80itgSwrKnOlGiaOD9OpRSyqNffUWkm4hsE5EdIjIyh9eLishk5+u/iUisJ+PB4cDMuB9z6A+GnXuQl1YKexNTATQJKKUClscSgYgEAx8B3YF6QH8RqXfRavcAJ40xNYB3gNc9FQ/7V5I69kZk8wz+nT6A5CqdWfBoO2KjQj22SaWU8gWe/BrcHNhhjNkFICKTgN7A5mzr9AZecD6eAnwoImLcXa6zfyVmfA+KZ6aTQRCt2nfjmS7NtUmcUkrh2UtDlYD92Z4nOJfluI4xJgNIAiIv/iARGSoiq0Vk9bFjx/IfyZ6lSGYmAMEidCr2pyYBpZRy8onyGGPMGGNMvDEmvkyZMvn/gNi2UKgoSDASXMR6rpRSCvDspaEDQOVsz6Ody3JaJ0FECgHhQKLbI6ncHAbNhD1LrSRQubnbN6GUUr7Kk4lgFVBTRKpiHfD7AQMuWmcmMAhYDtwK/Oz28YEslZtrAlBKqRx4LBEYYzJEZBgwHwgGxhljNonIS8BqY8xMYCzwlYjsAE5gJQullFJe5NHieWPMXGDuRctGZXucBtzmyRiUUkrlzicGi5VSSnmOJgKllApwmgiUUirAaSJQSqkAJ742+YqIHAP2XuHbo4DjbgzHF+g+Bwbd58BwNftcxRiT4x25PpcIroaIrDbGxNsdhzfpPgcG3efA4Kl91ktDSikV4DQRKKVUgAu0RDDG7gBsoPscGHSfA4NH9jmgxgiUUkpdKtDOCJRSSl1EE4FSSgU4v0wEItJNRLaJyA4RGZnD60VFZLLz9d9EJNb7UbqXC/s8XEQ2i8h6EflJRKrYEac75bXP2da7RUSMiPh8qaEr+ywitzv/rjeJyARvx+huLvzbjhGRhSKy1vnvu4cdcbqLiIwTkaMisvEyr4uIvO/8fawXkaZXvVFjjF/9YLW83glUA4oAfwD1LlrnAeAT5+N+wGS74/bCPl8HFHc+vj8Q9tm5XhiwBFgBxNsdtxf+nmsCa4HSzudl7Y7bC/s8Brjf+bgesMfuuK9yn9sBTYGNl3m9B/ADIEBL4Ler3aY/nhE0B3YYY3YZY84Dk4DeF63TG/jC+XgK0El8exLjPPfZGLPQGJPqfLoCa8Y4X+bK3zPAy8DrQJo3g/MQV/b5XuAjY8xJAGPMUS/H6G6u7LMBSjofhwMHvRif2xljlmDNz3I5vYEvjWUFUEpEKlzNNv0xEVQC9md7nuBcluM6xpgMIAmI9Ep0nuHKPmd3D9Y3Cl+W5z47T5krG2PmeDMwD3Ll77kWUEtEfhWRFSLSzWvReYYr+/wCcKeIJGDNf/KQd0KzTX7/v+fJoxPTqIJHRO4E4oH2dsfiSSISBLwNDLY5FG8rhHV5qAPWWd8SEWlojDlla1Se1R8Yb4x5S0RaYc162MAY47A7MF/hj2cEB4DK2Z5HO5fluI6IFMI6nUz0SnSe4co+IyKdgWeAXsaYc16KzVPy2ucwoAGwSET2YF1LnenjA8au/D0nADONMenGmN3AdqzE4Ktc2ed7gG8BjDHLgRCs5mz+yqX/7/nhj4lgFVBTRKqKSBGsweCZF60zExjkfHwr8LNxjsL4qDz3WUSaAJ9iJQFfv24MeeyzMSbJGBNljIk1xsRijYv0Msastidct3Dl3/YMrLMBRCQK61LRLm8G6Wau7PM+oBOAiNTFSgTHvBqld80E7nJWD7UEkowxh67mA/3u0pAxJkNEhgHzsSoOxhljNonIS8BqY8xMYCzW6eMOrEGZfvZFfPVc3Oc3gBLAd85x8X3GmF62BX2VXNxnv+LiPs8HuorIZiATeMIY47Nnuy7u82PAZyLyKNbA8WBf/mInIhOxknmUc9zjeaAwgDHmE6xxkB7ADiAVGHLV2/Th35dSSik38MdLQ0oppfJBE4FSSgU4TQRKKRXgNBEopVSA00SglFIBThOBKpBEJFNE1mX7ic1l3RQ3bG+8iOx2but35x2q+f2Mz0WknvPx0xe9tuxqY3R+TtbvZaOIzBKRUnms39jXu3Eqz9PyUVUgiUiKMaaEu9fN5TPGA7ONMVNEpCvwpjEm7io+76pjyutzReQLYLsx5t+5rD8Yq+vqMHfHovyHnhEonyAiJZzzKPwuIhtE5JJOoyJSQUSWZPvG3Na5vKuILHe+9zsRyesAvQSo4XzvcOdnbRSRfzmXhYrIHBH5w7m8r3P5IhGJF5HRQDFnHN84X0tx/jlJRG7IFvN4EblVRIJF5A0RWeXsMX+fC7+W5TibjYlIc+c+rhWRZSJS23kn7ktAX2csfZ2xjxORlc51c+rYqgKN3b239Ud/cvrBuit2nfNnOtZd8CWdr0Vh3VWZdUab4vzzMeAZ5+NgrH5DUVgH9lDn8hHAqBy2Nx641fn4NuA34BpgAxCKdVf2JqAJcAvwWbb3hjv/XIRzzoOsmLKtkxXjzcAXzsdFsLpIFgOGAs86lxcFVgNVc4gzJdv+fQd0cz4vCRRyPu4MTHU+Hgx8mO39rwJ3Oh+XwupFFGr337f+2Pvjdy0mlN84a4xpnPVERAoDr4pIO8CB9U24HHA423tWAeOc684wxqwTkfZYk5X86mytUQTrm3RO3hCRZ7H61NyD1b9mujHmjDOGaUBbYB7wloi8jnU5aWk+9usH4D0RKQp0A5YYY846L0fFicitzvXCsZrF7b7o/cVEZJ1z/7cA/8u2/hciUhOrzULhy2y/K9BLRB53Pg8BYpyfpQKUJgLlK+4AygDXGGPSxeooGpJ9BWPMEmeiuAEYLyJvAyeB/xlj+ruwjSeMMVOynohIp5xWMsZsF2uugx7AKyLykzHmJVd2whiTJiKLgOuBvlgTrYA129RDxpj5eXzEWWNMYxEpjtV/50HgfawJeBYaY252Dqwvusz7BbjFGLPNlXhVYNAxAuUrwoGjziRwHXDJnMtizcN8xBjzGfA51nR/K4A2IpJ1zT9URGq5uM2lwE0iUlxEQrEu6ywVkYpAqjHma6xmfjnNGZvuPDPJyWSsRmFZZxdgHdTvz3qPiNRybjNHxppt7mHgMfmrlXpWK+LB2VZNxrpElmU+8JA4T4/E6kqrApwmAuUrvgHiRWQDcBewNYd1OgB/iMharG/b7xljjmEdGCeKyHqsy0J1XNmgMeZ3rLGDlVhjBp8bY9YCDYGVzks0zwOv5PD2McD6rMHiiyzAmhjoR2NNvwhW4toM/C7WpOWfkscZuzOW9VgTs/wHeM2579nftxColzVYjHXmUNgZ2ybncxXgtHxUKaUCnJ4RKKVUgNNEoJRSAU4TgVJKBThNBEopFeA0ESilVIDTRKCUUgFOE4FSSgW4/weA8iXz7c08YQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe1cf13-a302-4b6f-bfcf-915480c2eae2",
        "id": "4TlvS1vr4L1x"
      },
      "source": [
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.XGBoostLimitDepthEstimator object at 0x7f80007e2350>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed34e575-2bf9-4ca3-b301-1505bb8f6e60",
        "id": "7G0K7NZg4L1y"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: xgb_limitdepth\n",
            "Best hyperparmeter config: {'n_estimators': 289, 'max_depth': 12, 'min_child_weight': 17.317952259324176, 'learning_rate': 0.04704558926576879, 'subsample': 0.827351358517848, 'colsample_bylevel': 0.4530063520214701, 'colsample_bytree': 0.6359444321807614, 'reg_alpha': 0.0009765625, 'reg_lambda': 324.4066831726308, 'FLAML_sample_size': 142578}\n",
            "Best accuracy on validation data: 0.6598\n",
            "Training duration of best run: 65.14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t1aACXJ4L1y"
      },
      "source": [
        "### W/H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6c4358-9b6a-49d6-a1af-af09af7aa206",
        "id": "-QDiCbEL4L1z"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x2_train, y_train=y2_train_np,\n",
        "           **automl_settings)\n",
        "# Export the best model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 13:39:10] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 13:39:10] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 13:39:10] {1963} INFO - Evaluation method: holdout\n",
            "[flaml.automl: 12-26 13:39:10] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 13:39:10] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 13:39:10] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:10] {2461} INFO - Estimated sufficient time budget=8396s. Estimated necessary time budget=206s.\n",
            "[flaml.automl: 12-26 13:39:10] {2541} INFO -  at 1.6s,\testimator lgbm's best error=0.4283,\tbest estimator lgbm's best error=0.4283\n",
            "[flaml.automl: 12-26 13:39:10] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:10] {2541} INFO -  at 1.7s,\testimator lgbm's best error=0.4283,\tbest estimator lgbm's best error=0.4283\n",
            "[flaml.automl: 12-26 13:39:10] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:10] {2541} INFO -  at 1.8s,\testimator lgbm's best error=0.3850,\tbest estimator lgbm's best error=0.3850\n",
            "[flaml.automl: 12-26 13:39:10] {2347} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 1.8s,\testimator xgboost's best error=0.3929,\tbest estimator lgbm's best error=0.3850\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 1.9s,\testimator lgbm's best error=0.3519,\tbest estimator lgbm's best error=0.3519\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.0s,\testimator lgbm's best error=0.3519,\tbest estimator lgbm's best error=0.3519\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.0s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.1s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.2s,\testimator lgbm's best error=0.3461,\tbest estimator lgbm's best error=0.3461\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.3s,\testimator lgbm's best error=0.3420,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.4s,\testimator xgboost's best error=0.3921,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:39:11] {2541} INFO -  at 2.7s,\testimator extra_tree's best error=0.4180,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:11] {2347} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 12-26 13:39:12] {2541} INFO -  at 3.0s,\testimator rf's best error=0.3988,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:12] {2347} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 12-26 13:39:12] {2541} INFO -  at 3.4s,\testimator rf's best error=0.3775,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:12] {2347} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:12] {2541} INFO -  at 3.4s,\testimator lgbm's best error=0.3420,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:12] {2347} INFO - iteration 15, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:39:12] {2541} INFO -  at 3.8s,\testimator extra_tree's best error=0.3852,\tbest estimator lgbm's best error=0.3420\n",
            "[flaml.automl: 12-26 13:39:12] {2347} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:13] {2541} INFO -  at 4.2s,\testimator lgbm's best error=0.3385,\tbest estimator lgbm's best error=0.3385\n",
            "[flaml.automl: 12-26 13:39:13] {2347} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:39:13] {2541} INFO -  at 4.5s,\testimator extra_tree's best error=0.3852,\tbest estimator lgbm's best error=0.3385\n",
            "[flaml.automl: 12-26 13:39:13] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:14] {2541} INFO -  at 5.1s,\testimator lgbm's best error=0.3385,\tbest estimator lgbm's best error=0.3385\n",
            "[flaml.automl: 12-26 13:39:14] {2347} INFO - iteration 19, current learner rf\n",
            "[flaml.automl: 12-26 13:39:14] {2541} INFO -  at 5.5s,\testimator rf's best error=0.3775,\tbest estimator lgbm's best error=0.3385\n",
            "[flaml.automl: 12-26 13:39:14] {2347} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:14] {2541} INFO -  at 5.8s,\testimator lgbm's best error=0.3385,\tbest estimator lgbm's best error=0.3385\n",
            "[flaml.automl: 12-26 13:39:14] {2347} INFO - iteration 21, current learner catboost\n",
            "[flaml.automl: 12-26 13:39:15] {2541} INFO -  at 6.3s,\testimator catboost's best error=0.3368,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:15] {2347} INFO - iteration 22, current learner catboost\n",
            "[flaml.automl: 12-26 13:39:22] {2541} INFO -  at 13.7s,\testimator catboost's best error=0.3368,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:22] {2347} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:23] {2541} INFO -  at 14.1s,\testimator lgbm's best error=0.3385,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:23] {2347} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:23] {2541} INFO -  at 14.6s,\testimator lgbm's best error=0.3385,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:23] {2347} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:39:24] {2541} INFO -  at 15.1s,\testimator extra_tree's best error=0.3831,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:24] {2347} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:24] {2541} INFO -  at 15.2s,\testimator xgboost's best error=0.3849,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:24] {2347} INFO - iteration 27, current learner rf\n",
            "[flaml.automl: 12-26 13:39:24] {2541} INFO -  at 15.6s,\testimator rf's best error=0.3775,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:24] {2347} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:24] {2541} INFO -  at 15.7s,\testimator xgboost's best error=0.3775,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:24] {2347} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:24] {2541} INFO -  at 15.8s,\testimator xgboost's best error=0.3775,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:24] {2347} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:25] {2541} INFO -  at 15.9s,\testimator xgboost's best error=0.3775,\tbest estimator catboost's best error=0.3368\n",
            "[flaml.automl: 12-26 13:39:25] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:26] {2541} INFO -  at 16.9s,\testimator lgbm's best error=0.3243,\tbest estimator lgbm's best error=0.3243\n",
            "[flaml.automl: 12-26 13:39:26] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:27] {2541} INFO -  at 18.0s,\testimator lgbm's best error=0.3243,\tbest estimator lgbm's best error=0.3243\n",
            "[flaml.automl: 12-26 13:39:27] {2347} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:28] {2541} INFO -  at 19.3s,\testimator lgbm's best error=0.3243,\tbest estimator lgbm's best error=0.3243\n",
            "[flaml.automl: 12-26 13:39:28] {2347} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:28] {2541} INFO -  at 19.5s,\testimator xgboost's best error=0.3498,\tbest estimator lgbm's best error=0.3243\n",
            "[flaml.automl: 12-26 13:39:28] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:29] {2541} INFO -  at 20.3s,\testimator lgbm's best error=0.3192,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:29] {2347} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:29] {2541} INFO -  at 20.5s,\testimator xgboost's best error=0.3459,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:29] {2347} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:29] {2541} INFO -  at 20.6s,\testimator xgboost's best error=0.3459,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:29] {2347} INFO - iteration 38, current learner catboost\n",
            "[flaml.automl: 12-26 13:39:31] {2541} INFO -  at 22.6s,\testimator catboost's best error=0.3264,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:31] {2347} INFO - iteration 39, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:32] {2541} INFO -  at 22.9s,\testimator xgb_limitdepth's best error=0.3535,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:32] {2347} INFO - iteration 40, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:32] {2541} INFO -  at 23.1s,\testimator xgb_limitdepth's best error=0.3535,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:32] {2347} INFO - iteration 41, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:32] {2541} INFO -  at 23.5s,\testimator xgb_limitdepth's best error=0.3535,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:32] {2347} INFO - iteration 42, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:32] {2541} INFO -  at 23.8s,\testimator xgb_limitdepth's best error=0.3535,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:32] {2347} INFO - iteration 43, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:33] {2541} INFO -  at 24.1s,\testimator xgb_limitdepth's best error=0.3535,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:33] {2347} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:34] {2541} INFO -  at 25.2s,\testimator lgbm's best error=0.3192,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:34] {2347} INFO - iteration 45, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:35] {2541} INFO -  at 26.2s,\testimator xgb_limitdepth's best error=0.3400,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:35] {2347} INFO - iteration 46, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:35] {2541} INFO -  at 26.6s,\testimator xgb_limitdepth's best error=0.3400,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:35] {2347} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:35] {2541} INFO -  at 26.8s,\testimator xgboost's best error=0.3459,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:35] {2347} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:36] {2541} INFO -  at 27.1s,\testimator lgbm's best error=0.3192,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:36] {2347} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:36] {2541} INFO -  at 27.3s,\testimator xgboost's best error=0.3459,\tbest estimator lgbm's best error=0.3192\n",
            "[flaml.automl: 12-26 13:39:36] {2347} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:39] {2541} INFO -  at 30.2s,\testimator lgbm's best error=0.3172,\tbest estimator lgbm's best error=0.3172\n",
            "[flaml.automl: 12-26 13:39:39] {2347} INFO - iteration 51, current learner rf\n",
            "[flaml.automl: 12-26 13:39:39] {2541} INFO -  at 30.5s,\testimator rf's best error=0.3743,\tbest estimator lgbm's best error=0.3172\n",
            "[flaml.automl: 12-26 13:39:39] {2347} INFO - iteration 52, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:39:41] {2541} INFO -  at 32.4s,\testimator xgb_limitdepth's best error=0.3310,\tbest estimator lgbm's best error=0.3172\n",
            "[flaml.automl: 12-26 13:39:41] {2347} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:45] {2541} INFO -  at 35.8s,\testimator lgbm's best error=0.3108,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:45] {2347} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:48] {2541} INFO -  at 39.0s,\testimator lgbm's best error=0.3108,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:48] {2347} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:52] {2541} INFO -  at 43.1s,\testimator lgbm's best error=0.3108,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:52] {2347} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-26 13:39:56] {2541} INFO -  at 47.6s,\testimator lgbm's best error=0.3108,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:56] {2347} INFO - iteration 57, current learner lrl1\n",
            "[flaml.automl: 12-26 13:39:57] {2541} INFO -  at 48.1s,\testimator lrl1's best error=0.3629,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:57] {2347} INFO - iteration 58, current learner lrl1\n",
            "[flaml.automl: 12-26 13:39:57] {2541} INFO -  at 48.6s,\testimator lrl1's best error=0.3629,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:57] {2347} INFO - iteration 59, current learner lrl1\n",
            "[flaml.automl: 12-26 13:39:58] {2541} INFO -  at 49.2s,\testimator lrl1's best error=0.3627,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:58] {2347} INFO - iteration 60, current learner rf\n",
            "[flaml.automl: 12-26 13:39:58] {2541} INFO -  at 49.6s,\testimator rf's best error=0.3743,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:58] {2347} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 12-26 13:39:58] {2541} INFO -  at 49.8s,\testimator xgboost's best error=0.3459,\tbest estimator lgbm's best error=0.3108\n",
            "[flaml.automl: 12-26 13:39:58] {2347} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl: 12-26 13:40:05] {2541} INFO -  at 56.1s,\testimator lgbm's best error=0.3082,\tbest estimator lgbm's best error=0.3082\n",
            "[flaml.automl: 12-26 13:40:05] {2347} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-26 13:40:05] {2541} INFO -  at 56.3s,\testimator xgboost's best error=0.3419,\tbest estimator lgbm's best error=0.3082\n",
            "[flaml.automl: 12-26 13:40:05] {2347} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl: 12-26 13:40:08] {2541} INFO -  at 59.7s,\testimator lgbm's best error=0.3082,\tbest estimator lgbm's best error=0.3082\n",
            "[flaml.automl: 12-26 13:40:08] {2347} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 12-26 13:40:09] {2541} INFO -  at 59.9s,\testimator xgboost's best error=0.3419,\tbest estimator lgbm's best error=0.3082\n",
            "[flaml.automl: 12-26 13:40:09] {2347} INFO - iteration 66, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:40:11] {2541} INFO -  at 62.1s,\testimator xgb_limitdepth's best error=0.3310,\tbest estimator lgbm's best error=0.3082\n",
            "[flaml.automl: 12-26 13:40:11] {2347} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl: 12-26 13:40:37] {2541} INFO -  at 88.3s,\testimator lgbm's best error=0.3061,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:40:37] {2347} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 12-26 13:40:37] {2541} INFO -  at 88.7s,\testimator xgboost's best error=0.3419,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:40:37] {2347} INFO - iteration 69, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:40:38] {2541} INFO -  at 89.0s,\testimator extra_tree's best error=0.3831,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:40:38] {2347} INFO - iteration 70, current learner catboost\n",
            "[flaml.automl: 12-26 13:41:07] {2541} INFO -  at 118.3s,\testimator catboost's best error=0.3264,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:07] {2347} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl: 12-26 13:41:13] {2541} INFO -  at 124.7s,\testimator lgbm's best error=0.3061,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:13] {2347} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 12-26 13:41:14] {2541} INFO -  at 124.9s,\testimator xgboost's best error=0.3419,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:14] {2347} INFO - iteration 73, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:41:14] {2541} INFO -  at 125.3s,\testimator extra_tree's best error=0.3755,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:14] {2347} INFO - iteration 74, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:41:14] {2541} INFO -  at 125.8s,\testimator extra_tree's best error=0.3755,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:14] {2347} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:41:16] {2541} INFO -  at 127.4s,\testimator xgb_limitdepth's best error=0.3310,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:16] {2347} INFO - iteration 76, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:41:17] {2541} INFO -  at 127.9s,\testimator extra_tree's best error=0.3714,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:17] {2347} INFO - iteration 77, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:41:19] {2541} INFO -  at 130.5s,\testimator xgb_limitdepth's best error=0.3310,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:19] {2347} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 12-26 13:41:26] {2541} INFO -  at 137.4s,\testimator lgbm's best error=0.3061,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:41:26] {2347} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl: 12-26 13:42:32] {2541} INFO -  at 203.5s,\testimator lgbm's best error=0.3061,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:32] {2347} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:42:33] {2541} INFO -  at 204.0s,\testimator extra_tree's best error=0.3714,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:33] {2347} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:33] {2541} INFO -  at 204.3s,\testimator xgboost's best error=0.3419,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:33] {2347} INFO - iteration 82, current learner rf\n",
            "[flaml.automl: 12-26 13:42:33] {2541} INFO -  at 204.6s,\testimator rf's best error=0.3709,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:33] {2347} INFO - iteration 83, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:42:35] {2541} INFO -  at 206.0s,\testimator xgb_limitdepth's best error=0.3310,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:35] {2347} INFO - iteration 84, current learner rf\n",
            "[flaml.automl: 12-26 13:42:35] {2541} INFO -  at 206.4s,\testimator rf's best error=0.3578,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:35] {2347} INFO - iteration 85, current learner rf\n",
            "[flaml.automl: 12-26 13:42:35] {2541} INFO -  at 206.8s,\testimator rf's best error=0.3578,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:35] {2347} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:36] {2541} INFO -  at 207.3s,\testimator xgboost's best error=0.3347,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:36] {2347} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:42:36] {2541} INFO -  at 207.8s,\testimator extra_tree's best error=0.3714,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:36] {2347} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:37] {2541} INFO -  at 208.2s,\testimator xgboost's best error=0.3347,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:37] {2347} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:39] {2541} INFO -  at 209.9s,\testimator xgboost's best error=0.3320,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:39] {2347} INFO - iteration 90, current learner rf\n",
            "[flaml.automl: 12-26 13:42:39] {2541} INFO -  at 210.3s,\testimator rf's best error=0.3578,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:39] {2347} INFO - iteration 91, current learner rf\n",
            "[flaml.automl: 12-26 13:42:39] {2541} INFO -  at 210.8s,\testimator rf's best error=0.3578,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:39] {2347} INFO - iteration 92, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:42:48] {2541} INFO -  at 219.2s,\testimator xgb_limitdepth's best error=0.3176,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:48] {2347} INFO - iteration 93, current learner rf\n",
            "[flaml.automl: 12-26 13:42:48] {2541} INFO -  at 219.7s,\testimator rf's best error=0.3578,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:48] {2347} INFO - iteration 94, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:42:53] {2541} INFO -  at 224.3s,\testimator xgb_limitdepth's best error=0.3176,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:53] {2347} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:54] {2541} INFO -  at 225.1s,\testimator xgboost's best error=0.3320,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:54] {2347} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 12-26 13:42:59] {2541} INFO -  at 230.0s,\testimator xgboost's best error=0.3266,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:59] {2347} INFO - iteration 97, current learner rf\n",
            "[flaml.automl: 12-26 13:42:59] {2541} INFO -  at 230.5s,\testimator rf's best error=0.3569,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:42:59] {2347} INFO - iteration 98, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:43:15] {2541} INFO -  at 246.6s,\testimator xgb_limitdepth's best error=0.3121,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:15] {2347} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 12-26 13:43:19] {2541} INFO -  at 250.3s,\testimator xgboost's best error=0.3255,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:19] {2347} INFO - iteration 100, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:43:19] {2541} INFO -  at 250.7s,\testimator extra_tree's best error=0.3651,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:19] {2347} INFO - iteration 101, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:43:20] {2541} INFO -  at 251.2s,\testimator extra_tree's best error=0.3645,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:20] {2347} INFO - iteration 102, current learner rf\n",
            "[flaml.automl: 12-26 13:43:20] {2541} INFO -  at 251.6s,\testimator rf's best error=0.3569,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:20] {2347} INFO - iteration 103, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:43:29] {2541} INFO -  at 259.9s,\testimator xgb_limitdepth's best error=0.3121,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:29] {2347} INFO - iteration 104, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:43:29] {2541} INFO -  at 260.4s,\testimator extra_tree's best error=0.3645,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:29] {2347} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl: 12-26 13:43:51] {2541} INFO -  at 282.4s,\testimator lgbm's best error=0.3061,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:51] {2347} INFO - iteration 106, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:43:51] {2541} INFO -  at 282.8s,\testimator extra_tree's best error=0.3645,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:43:51] {2347} INFO - iteration 107, current learner catboost\n",
            "[flaml.automl: 12-26 13:44:02] {2541} INFO -  at 293.7s,\testimator catboost's best error=0.3189,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:44:02] {2347} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 12-26 13:44:07] {2541} INFO -  at 298.4s,\testimator xgboost's best error=0.3255,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:44:07] {2347} INFO - iteration 109, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:44:40] {2541} INFO -  at 331.0s,\testimator xgb_limitdepth's best error=0.3093,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:44:40] {2347} INFO - iteration 110, current learner catboost\n",
            "[flaml.automl: 12-26 13:45:57] {2541} INFO -  at 408.6s,\testimator catboost's best error=0.3189,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:45:57] {2347} INFO - iteration 111, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:46:16] {2541} INFO -  at 427.3s,\testimator xgb_limitdepth's best error=0.3093,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:46:16] {2347} INFO - iteration 112, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:46:17] {2541} INFO -  at 427.9s,\testimator extra_tree's best error=0.3645,\tbest estimator lgbm's best error=0.3061\n",
            "[flaml.automl: 12-26 13:46:17] {2347} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl: 12-26 13:46:44] {2541} INFO -  at 455.0s,\testimator lgbm's best error=0.3028,\tbest estimator lgbm's best error=0.3028\n",
            "[flaml.automl: 12-26 13:46:44] {2347} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:47:40] {2541} INFO -  at 511.0s,\testimator xgb_limitdepth's best error=0.2956,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:47:40] {2347} INFO - iteration 115, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:48:06] {2541} INFO -  at 537.8s,\testimator xgb_limitdepth's best error=0.2956,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:48:06] {2347} INFO - iteration 116, current learner lrl1\n",
            "[flaml.automl: 12-26 13:48:07] {2541} INFO -  at 538.3s,\testimator lrl1's best error=0.3627,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:48:07] {2347} INFO - iteration 117, current learner rf\n",
            "[flaml.automl: 12-26 13:48:07] {2541} INFO -  at 538.7s,\testimator rf's best error=0.3569,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:48:07] {2347} INFO - iteration 118, current learner rf\n",
            "[flaml.automl: 12-26 13:48:08] {2541} INFO -  at 539.3s,\testimator rf's best error=0.3553,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:48:08] {2347} INFO - iteration 119, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:49:09] {2541} INFO -  at 600.0s,\testimator xgb_limitdepth's best error=0.2956,\tbest estimator xgb_limitdepth's best error=0.2956\n",
            "[flaml.automl: 12-26 13:50:11] {2753} INFO - retrain xgb_limitdepth for 61.9s\n",
            "[flaml.automl: 12-26 13:50:11] {2758} INFO - retrained model: XGBClassifier(colsample_bylevel=0.6274332478496758,\n",
            "              colsample_bytree=0.7722133869187113,\n",
            "              learning_rate=0.221794117367674, max_depth=7,\n",
            "              min_child_weight=2.7720684284418464, n_estimators=333, n_jobs=-1,\n",
            "              reg_alpha=0.0017607866203119683, reg_lambda=0.14322775448429365,\n",
            "              subsample=1.0, use_label_encoder=False, verbosity=0)\n",
            "[flaml.automl: 12-26 13:50:11] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 13:50:11] {2138} INFO - Time taken to find the best model: 510.96012568473816\n",
            "[flaml.automl: 12-26 13:50:11] {2152} WARNING - Time taken to find the best model is 85% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "5319e381-719f-483c-ed44-e2af6cdf52d1",
        "id": "C4FUqt-t4L1z"
      },
      "source": [
        "create_auc_roc(y2_test_np, automl, x2_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80069, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.707\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd493509-4ea4-47e5-aabb-0d42467a47e8",
        "id": "GqEQcLOX4L10"
      },
      "source": [
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.XGBoostLimitDepthEstimator object at 0x7f7fff294dd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363dc8db-14ac-475a-fe2d-3940944a531f",
        "id": "OBUsgB2R4L10"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: xgb_limitdepth\n",
            "Best hyperparmeter config: {'n_estimators': 333, 'max_depth': 7, 'min_child_weight': 2.7720684284418464, 'learning_rate': 0.221794117367674, 'subsample': 1.0, 'colsample_bylevel': 0.6274332478496758, 'colsample_bytree': 0.7722133869187113, 'reg_alpha': 0.0017607866203119683, 'reg_lambda': 0.14322775448429365, 'FLAML_sample_size': 168142}\n",
            "Best accuracy on validation data: 0.7044\n",
            "Training duration of best run: 61.86 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmYS013R4L11"
      },
      "source": [
        "### HAWH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8da1154-fecb-4af5-82ae-0039c8f8a44e",
        "id": "hB4oUh3M4L11"
      },
      "source": [
        "\n",
        "automl.fit(X_train=x3_train, y_train=y3_train_np,\n",
        "           **automl_settings)\n",
        "# print(automl.predict_proba(X_train).shape)\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-26 13:50:14] {1957} INFO - task = classification\n",
            "[flaml.automl: 12-26 13:50:14] {1959} INFO - Data split method: stratified\n",
            "[flaml.automl: 12-26 13:50:14] {1963} INFO - Evaluation method: holdout\n",
            "[flaml.automl: 12-26 13:50:14] {2055} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 12-26 13:50:14] {2107} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 12-26 13:50:14] {2347} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2461} INFO - Estimated sufficient time budget=12279s. Estimated necessary time budget=301s.\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.0s,\testimator lgbm's best error=0.3401,\tbest estimator lgbm's best error=0.3401\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.1s,\testimator lgbm's best error=0.3401,\tbest estimator lgbm's best error=0.3401\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.1s,\testimator lgbm's best error=0.3284,\tbest estimator lgbm's best error=0.3284\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.2s,\testimator xgboost's best error=0.3377,\tbest estimator lgbm's best error=0.3284\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.3s,\testimator lgbm's best error=0.2814,\tbest estimator lgbm's best error=0.2814\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.4s,\testimator lgbm's best error=0.2814,\tbest estimator lgbm's best error=0.2814\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.4s,\testimator lgbm's best error=0.2658,\tbest estimator lgbm's best error=0.2658\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.5s,\testimator lgbm's best error=0.2658,\tbest estimator lgbm's best error=0.2658\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.6s,\testimator lgbm's best error=0.2658,\tbest estimator lgbm's best error=0.2658\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.7s,\testimator lgbm's best error=0.2567,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.8s,\testimator xgboost's best error=0.3377,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:15] {2541} INFO -  at 2.9s,\testimator xgboost's best error=0.3111,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:15] {2347} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:16] {2541} INFO -  at 3.2s,\testimator extra_tree's best error=0.3487,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:16] {2347} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 12-26 13:50:16] {2541} INFO -  at 3.5s,\testimator rf's best error=0.3513,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:16] {2347} INFO - iteration 14, current learner rf\n",
            "[flaml.automl: 12-26 13:50:16] {2541} INFO -  at 3.9s,\testimator rf's best error=0.2997,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:16] {2347} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:16] {2541} INFO -  at 3.9s,\testimator xgboost's best error=0.3010,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:16] {2347} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:17] {2541} INFO -  at 4.0s,\testimator lgbm's best error=0.2567,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:17] {2347} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:17] {2541} INFO -  at 4.4s,\testimator extra_tree's best error=0.3148,\tbest estimator lgbm's best error=0.2567\n",
            "[flaml.automl: 12-26 13:50:17] {2347} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:17] {2541} INFO -  at 4.8s,\testimator lgbm's best error=0.2402,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:17] {2347} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:17] {2541} INFO -  at 4.9s,\testimator xgboost's best error=0.3010,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:17] {2347} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:18] {2541} INFO -  at 5.5s,\testimator lgbm's best error=0.2402,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:18] {2347} INFO - iteration 21, current learner rf\n",
            "[flaml.automl: 12-26 13:50:18] {2541} INFO -  at 5.9s,\testimator rf's best error=0.2997,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:18] {2347} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:19] {2541} INFO -  at 6.2s,\testimator lgbm's best error=0.2402,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:19] {2347} INFO - iteration 23, current learner catboost\n",
            "[flaml.automl: 12-26 13:50:20] {2541} INFO -  at 7.6s,\testimator catboost's best error=0.2405,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:20] {2347} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:21] {2541} INFO -  at 8.0s,\testimator lgbm's best error=0.2402,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:21] {2347} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:21] {2541} INFO -  at 8.4s,\testimator extra_tree's best error=0.3148,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:21] {2347} INFO - iteration 26, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:21] {2541} INFO -  at 8.8s,\testimator extra_tree's best error=0.3148,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:21] {2347} INFO - iteration 27, current learner rf\n",
            "[flaml.automl: 12-26 13:50:22] {2541} INFO -  at 9.3s,\testimator rf's best error=0.2997,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:22] {2347} INFO - iteration 28, current learner catboost\n",
            "[flaml.automl: 12-26 13:50:36] {2541} INFO -  at 23.9s,\testimator catboost's best error=0.2405,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:36] {2347} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:37] {2541} INFO -  at 24.0s,\testimator xgboost's best error=0.3010,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:37] {2347} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:37] {2541} INFO -  at 24.3s,\testimator extra_tree's best error=0.3148,\tbest estimator lgbm's best error=0.2402\n",
            "[flaml.automl: 12-26 13:50:37] {2347} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:37] {2541} INFO -  at 24.9s,\testimator lgbm's best error=0.2347,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:37] {2347} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:39] {2541} INFO -  at 26.1s,\testimator lgbm's best error=0.2347,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:39] {2347} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:39] {2541} INFO -  at 26.5s,\testimator lgbm's best error=0.2347,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:39] {2347} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:39] {2541} INFO -  at 26.7s,\testimator xgboost's best error=0.2716,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:39] {2347} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:40] {2541} INFO -  at 27.5s,\testimator lgbm's best error=0.2347,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:40] {2347} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:40] {2541} INFO -  at 27.7s,\testimator xgboost's best error=0.2657,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:40] {2347} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:50:41] {2541} INFO -  at 28.1s,\testimator extra_tree's best error=0.3148,\tbest estimator lgbm's best error=0.2347\n",
            "[flaml.automl: 12-26 13:50:41] {2347} INFO - iteration 38, current learner catboost\n",
            "[flaml.automl: 12-26 13:50:46] {2541} INFO -  at 33.2s,\testimator catboost's best error=0.2213,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:46] {2347} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:46] {2541} INFO -  at 33.4s,\testimator xgboost's best error=0.2657,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:46] {2347} INFO - iteration 40, current learner rf\n",
            "[flaml.automl: 12-26 13:50:46] {2541} INFO -  at 33.7s,\testimator rf's best error=0.2997,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:46] {2347} INFO - iteration 41, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:50:46] {2541} INFO -  at 34.0s,\testimator xgb_limitdepth's best error=0.2696,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:47] {2347} INFO - iteration 42, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:50:47] {2541} INFO -  at 34.3s,\testimator xgb_limitdepth's best error=0.2696,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:47] {2347} INFO - iteration 43, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:50:47] {2541} INFO -  at 34.6s,\testimator xgb_limitdepth's best error=0.2685,\tbest estimator catboost's best error=0.2213\n",
            "[flaml.automl: 12-26 13:50:47] {2347} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:48] {2541} INFO -  at 35.8s,\testimator lgbm's best error=0.2152,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:50:48] {2347} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:48] {2541} INFO -  at 36.0s,\testimator xgboost's best error=0.2606,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:50:48] {2347} INFO - iteration 46, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:50:49] {2541} INFO -  at 36.2s,\testimator xgb_limitdepth's best error=0.2685,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:50:49] {2347} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-26 13:50:49] {2541} INFO -  at 36.4s,\testimator xgboost's best error=0.2603,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:50:49] {2347} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 12-26 13:50:49] {2541} INFO -  at 36.8s,\testimator lgbm's best error=0.2152,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:50:49] {2347} INFO - iteration 49, current learner catboost\n",
            "[flaml.automl: 12-26 13:51:45] {2541} INFO -  at 92.5s,\testimator catboost's best error=0.2213,\tbest estimator lgbm's best error=0.2152\n",
            "[flaml.automl: 12-26 13:51:45] {2347} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 12-26 13:51:49] {2541} INFO -  at 96.1s,\testimator lgbm's best error=0.2103,\tbest estimator lgbm's best error=0.2103\n",
            "[flaml.automl: 12-26 13:51:49] {2347} INFO - iteration 51, current learner rf\n",
            "[flaml.automl: 12-26 13:51:49] {2541} INFO -  at 96.5s,\testimator rf's best error=0.2997,\tbest estimator lgbm's best error=0.2103\n",
            "[flaml.automl: 12-26 13:51:49] {2347} INFO - iteration 52, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:51:49] {2541} INFO -  at 96.9s,\testimator extra_tree's best error=0.3126,\tbest estimator lgbm's best error=0.2103\n",
            "[flaml.automl: 12-26 13:51:49] {2347} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-26 13:51:55] {2541} INFO -  at 102.0s,\testimator lgbm's best error=0.2060,\tbest estimator lgbm's best error=0.2060\n",
            "[flaml.automl: 12-26 13:51:55] {2347} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-26 13:51:58] {2541} INFO -  at 105.7s,\testimator lgbm's best error=0.2060,\tbest estimator lgbm's best error=0.2060\n",
            "[flaml.automl: 12-26 13:51:58] {2347} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:03] {2541} INFO -  at 110.3s,\testimator lgbm's best error=0.2060,\tbest estimator lgbm's best error=0.2060\n",
            "[flaml.automl: 12-26 13:52:03] {2347} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:08] {2541} INFO -  at 115.9s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:08] {2347} INFO - iteration 57, current learner rf\n",
            "[flaml.automl: 12-26 13:52:09] {2541} INFO -  at 116.3s,\testimator rf's best error=0.2997,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:09] {2347} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:13] {2541} INFO -  at 120.6s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:13] {2347} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:17] {2541} INFO -  at 124.6s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:17] {2347} INFO - iteration 60, current learner rf\n",
            "[flaml.automl: 12-26 13:52:18] {2541} INFO -  at 125.2s,\testimator rf's best error=0.2887,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:18] {2347} INFO - iteration 61, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "[flaml.automl: 12-26 13:52:18] {2541} INFO -  at 125.7s,\testimator lrl1's best error=0.2903,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:18] {2347} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-26 13:52:18] {2541} INFO -  at 125.9s,\testimator xgboost's best error=0.2603,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:18] {2347} INFO - iteration 63, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "[flaml.automl: 12-26 13:52:19] {2541} INFO -  at 126.5s,\testimator lrl1's best error=0.2897,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:19] {2347} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:27] {2541} INFO -  at 134.9s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:27] {2347} INFO - iteration 65, current learner rf\n",
            "[flaml.automl: 12-26 13:52:28] {2541} INFO -  at 135.3s,\testimator rf's best error=0.2887,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:28] {2347} INFO - iteration 66, current learner rf\n",
            "[flaml.automl: 12-26 13:52:28] {2541} INFO -  at 135.8s,\testimator rf's best error=0.2887,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:28] {2347} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:30] {2541} INFO -  at 137.7s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:30] {2347} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:32] {2541} INFO -  at 139.8s,\testimator lgbm's best error=0.1872,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:32] {2347} INFO - iteration 69, current learner rf\n",
            "[flaml.automl: 12-26 13:52:33] {2541} INFO -  at 140.3s,\testimator rf's best error=0.2710,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:33] {2347} INFO - iteration 70, current learner rf\n",
            "[flaml.automl: 12-26 13:52:33] {2541} INFO -  at 140.8s,\testimator rf's best error=0.2710,\tbest estimator lgbm's best error=0.1872\n",
            "[flaml.automl: 12-26 13:52:33] {2347} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:47] {2541} INFO -  at 154.8s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:47] {2347} INFO - iteration 72, current learner rf\n",
            "[flaml.automl: 12-26 13:52:48] {2541} INFO -  at 155.5s,\testimator rf's best error=0.2631,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:48] {2347} INFO - iteration 73, current learner rf\n",
            "[flaml.automl: 12-26 13:52:49] {2541} INFO -  at 156.0s,\testimator rf's best error=0.2631,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:49] {2347} INFO - iteration 74, current learner rf\n",
            "[flaml.automl: 12-26 13:52:50] {2541} INFO -  at 157.2s,\testimator rf's best error=0.2631,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:50] {2347} INFO - iteration 75, current learner lrl1\n",
            "[flaml.automl: 12-26 13:52:50] {2541} INFO -  at 157.7s,\testimator lrl1's best error=0.2897,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:50] {2347} INFO - iteration 76, current learner rf\n",
            "[flaml.automl: 12-26 13:52:51] {2541} INFO -  at 158.5s,\testimator rf's best error=0.2439,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:51] {2347} INFO - iteration 77, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:52:52] {2541} INFO -  at 159.1s,\testimator extra_tree's best error=0.2992,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:52] {2347} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl: 12-26 13:52:57] {2541} INFO -  at 164.9s,\testimator lgbm's best error=0.1755,\tbest estimator lgbm's best error=0.1755\n",
            "[flaml.automl: 12-26 13:52:57] {2347} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl: 12-26 13:53:15] {2541} INFO -  at 182.5s,\testimator lgbm's best error=0.1748,\tbest estimator lgbm's best error=0.1748\n",
            "[flaml.automl: 12-26 13:53:15] {2347} INFO - iteration 80, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:53:15] {2541} INFO -  at 182.9s,\testimator extra_tree's best error=0.2992,\tbest estimator lgbm's best error=0.1748\n",
            "[flaml.automl: 12-26 13:53:15] {2347} INFO - iteration 81, current learner rf\n",
            "[flaml.automl: 12-26 13:53:16] {2541} INFO -  at 183.5s,\testimator rf's best error=0.2439,\tbest estimator lgbm's best error=0.1748\n",
            "[flaml.automl: 12-26 13:53:16] {2347} INFO - iteration 82, current learner lgbm\n",
            "[flaml.automl: 12-26 13:53:34] {2541} INFO -  at 201.6s,\testimator lgbm's best error=0.1729,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:34] {2347} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:53:35] {2541} INFO -  at 202.2s,\testimator extra_tree's best error=0.2992,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:35] {2347} INFO - iteration 84, current learner lgbm\n",
            "[flaml.automl: 12-26 13:53:52] {2541} INFO -  at 219.8s,\testimator lgbm's best error=0.1729,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:52] {2347} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:53:53] {2541} INFO -  at 220.4s,\testimator extra_tree's best error=0.2798,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:53] {2347} INFO - iteration 86, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:53:53] {2541} INFO -  at 220.8s,\testimator extra_tree's best error=0.2798,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:53] {2347} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:53:54] {2541} INFO -  at 221.5s,\testimator extra_tree's best error=0.2776,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:54] {2347} INFO - iteration 88, current learner rf\n",
            "[flaml.automl: 12-26 13:53:55] {2541} INFO -  at 222.0s,\testimator rf's best error=0.2439,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:55] {2347} INFO - iteration 89, current learner rf\n",
            "[flaml.automl: 12-26 13:53:56] {2541} INFO -  at 223.1s,\testimator rf's best error=0.2439,\tbest estimator lgbm's best error=0.1729\n",
            "[flaml.automl: 12-26 13:53:56] {2347} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl: 12-26 13:54:40] {2541} INFO -  at 267.6s,\testimator lgbm's best error=0.1642,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:40] {2347} INFO - iteration 91, current learner rf\n",
            "[flaml.automl: 12-26 13:54:41] {2541} INFO -  at 268.5s,\testimator rf's best error=0.2339,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:41] {2347} INFO - iteration 92, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:54:41] {2541} INFO -  at 268.8s,\testimator xgb_limitdepth's best error=0.2680,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:41] {2347} INFO - iteration 93, current learner rf\n",
            "[flaml.automl: 12-26 13:54:42] {2541} INFO -  at 269.7s,\testimator rf's best error=0.2339,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:42] {2347} INFO - iteration 94, current learner lrl1\n",
            "[flaml.automl: 12-26 13:54:43] {2541} INFO -  at 270.8s,\testimator lrl1's best error=0.2884,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:43] {2347} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 12-26 13:54:44] {2541} INFO -  at 271.1s,\testimator xgboost's best error=0.2601,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:44] {2347} INFO - iteration 96, current learner rf\n",
            "[flaml.automl: 12-26 13:54:45] {2541} INFO -  at 272.1s,\testimator rf's best error=0.2339,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:54:45] {2347} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl: 12-26 13:55:03] {2541} INFO -  at 290.2s,\testimator lgbm's best error=0.1642,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:55:03] {2347} INFO - iteration 98, current learner lrl1\n",
            "[flaml.automl: 12-26 13:55:04] {2541} INFO -  at 291.4s,\testimator lrl1's best error=0.2883,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:55:04] {2347} INFO - iteration 99, current learner rf\n",
            "[flaml.automl: 12-26 13:55:05] {2541} INFO -  at 292.2s,\testimator rf's best error=0.2317,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:55:05] {2347} INFO - iteration 100, current learner catboost\n",
            "[flaml.automl: 12-26 13:55:23] {2541} INFO -  at 310.4s,\testimator catboost's best error=0.2169,\tbest estimator lgbm's best error=0.1642\n",
            "[flaml.automl: 12-26 13:55:23] {2347} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl: 12-26 13:56:01] {2541} INFO -  at 348.8s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:56:01] {2347} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl: 12-26 13:56:34] {2541} INFO -  at 381.1s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:56:34] {2347} INFO - iteration 103, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:56:34] {2541} INFO -  at 381.2s,\testimator xgb_limitdepth's best error=0.2680,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:56:34] {2347} INFO - iteration 104, current learner rf\n",
            "[flaml.automl: 12-26 13:56:35] {2541} INFO -  at 382.3s,\testimator rf's best error=0.2317,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:56:35] {2347} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl: 12-26 13:57:05] {2541} INFO -  at 412.1s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:05] {2347} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 12-26 13:57:05] {2541} INFO -  at 412.3s,\testimator xgboost's best error=0.2601,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:05] {2347} INFO - iteration 107, current learner lgbm\n",
            "[flaml.automl: 12-26 13:57:30] {2541} INFO -  at 437.2s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:30] {2347} INFO - iteration 108, current learner rf\n",
            "[flaml.automl: 12-26 13:57:30] {2541} INFO -  at 437.6s,\testimator rf's best error=0.2317,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:30] {2347} INFO - iteration 109, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:57:31] {2541} INFO -  at 438.3s,\testimator xgb_limitdepth's best error=0.2482,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:31] {2347} INFO - iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:57:32] {2541} INFO -  at 439.2s,\testimator xgb_limitdepth's best error=0.2482,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:32] {2347} INFO - iteration 111, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:57:32] {2541} INFO -  at 439.8s,\testimator xgb_limitdepth's best error=0.2482,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:32] {2347} INFO - iteration 112, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:57:33] {2541} INFO -  at 440.7s,\testimator xgb_limitdepth's best error=0.2470,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:33] {2347} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl: 12-26 13:57:53] {2541} INFO -  at 460.8s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:53] {2347} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-26 13:57:54] {2541} INFO -  at 461.6s,\testimator xgb_limitdepth's best error=0.2470,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:54] {2347} INFO - iteration 115, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:57:55] {2541} INFO -  at 462.1s,\testimator extra_tree's best error=0.2710,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:55] {2347} INFO - iteration 116, current learner lrl1\n",
            "[flaml.automl: 12-26 13:57:56] {2541} INFO -  at 463.2s,\testimator lrl1's best error=0.2883,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:56] {2347} INFO - iteration 117, current learner rf\n",
            "[flaml.automl: 12-26 13:57:57] {2541} INFO -  at 464.0s,\testimator rf's best error=0.2317,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:57] {2347} INFO - iteration 118, current learner rf\n",
            "[flaml.automl: 12-26 13:57:57] {2541} INFO -  at 464.9s,\testimator rf's best error=0.2296,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:57] {2347} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:57:58] {2541} INFO -  at 465.5s,\testimator extra_tree's best error=0.2710,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:58] {2347} INFO - iteration 120, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:57:59] {2541} INFO -  at 466.1s,\testimator extra_tree's best error=0.2513,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:57:59] {2347} INFO - iteration 121, current learner lgbm\n",
            "[flaml.automl: 12-26 13:58:15] {2541} INFO -  at 482.5s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:15] {2347} INFO - iteration 122, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:58:16] {2541} INFO -  at 483.1s,\testimator extra_tree's best error=0.2513,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:16] {2347} INFO - iteration 123, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:58:16] {2541} INFO -  at 483.4s,\testimator extra_tree's best error=0.2513,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:16] {2347} INFO - iteration 124, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:58:17] {2541} INFO -  at 484.3s,\testimator extra_tree's best error=0.2474,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:17] {2347} INFO - iteration 125, current learner extra_tree\n",
            "[flaml.automl: 12-26 13:58:18] {2541} INFO -  at 485.3s,\testimator extra_tree's best error=0.2359,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:18] {2347} INFO - iteration 126, current learner rf\n",
            "[flaml.automl: 12-26 13:58:19] {2541} INFO -  at 486.3s,\testimator rf's best error=0.2296,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:19] {2347} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl: 12-26 13:58:34] {2541} INFO -  at 501.7s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:34] {2347} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl: 12-26 13:58:47] {2541} INFO -  at 514.9s,\testimator lgbm's best error=0.1609,\tbest estimator lgbm's best error=0.1609\n",
            "[flaml.automl: 12-26 13:58:47] {2347} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl: 12-26 14:00:22] {2541} INFO -  at 610.0s,\testimator lgbm's best error=0.0747,\tbest estimator lgbm's best error=0.0747\n",
            "[flaml.automl: 12-26 14:10:46] {2753} INFO - retrain lgbm for 623.8s\n",
            "[flaml.automl: 12-26 14:10:46] {2758} INFO - retrained model: LGBMClassifier(colsample_bytree=0.5021054604173047,\n",
            "               learning_rate=0.06911280560506684, max_bin=255,\n",
            "               min_child_samples=6, n_estimators=5864, num_leaves=1495,\n",
            "               reg_alpha=0.016684774909953355, reg_lambda=0.14755503297987418,\n",
            "               verbose=-1)\n",
            "[flaml.automl: 12-26 14:10:46] {2136} INFO - fit succeeded\n",
            "[flaml.automl: 12-26 14:10:46] {2138} INFO - Time taken to find the best model: 609.9675512313843\n",
            "[flaml.automl: 12-26 14:10:46] {2152} WARNING - Time taken to find the best model is 102% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<flaml.model.LGBMEstimator object at 0x7f80120befd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b623a4e-4e17-4dda-ddf8-d96e0806b11f",
        "id": "nCQ3OLmh4L12"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 9284, 'num_leaves': 1495, 'min_child_samples': 6, 'learning_rate': 0.06911280560506684, 'log_max_bin': 8, 'colsample_bytree': 0.5021054604173047, 'reg_alpha': 0.016684774909953355, 'reg_lambda': 0.14755503297987418, 'FLAML_sample_size': 202990}\n",
            "Best accuracy on validation data: 0.9253\n",
            "Training duration of best run: 623.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "722a3ba2-200f-42fa-e6ed-904801571847",
        "id": "05a9ZbUF4L12"
      },
      "source": [
        "create_auc_roc(y3_test_np, automl, x3_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96663, 1)\n",
            "No Skill: ROC AUC=0.500\n",
            "Trained: ROC AUC=0.935\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPvCgxdz4L13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}